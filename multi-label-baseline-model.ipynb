{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zfeng0207/FIT3199-FYP/blob/dev%2Fzfeng/multi-label-baseline-model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0CUDImu9MEW",
        "outputId": "2b64c2d7-bcfa-4903-ed21-5468f05f2da5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "h0CUDImu9MEW"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "GfQLwvb-9N2C"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks (1)/ECG-MIMIC-main')"
      ],
      "id": "GfQLwvb-9N2C"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "K_PGqhC8-C_A"
      },
      "outputs": [],
      "source": [
        "!pip install -qqqq mlflow torchmetrics pytorch_lightning iterative-stratification"
      ],
      "id": "K_PGqhC8-C_A"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Labeling"
      ],
      "metadata": {
        "id": "7ukBVHAvTc8e"
      },
      "id": "7ukBVHAvTc8e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Multihot encode: Setting up target binary labels"
      ],
      "metadata": {
        "id": "CEFykubaW1Lt"
      },
      "id": "CEFykubaW1Lt"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import ast\n",
        "\n",
        "def multihot_encode(diagnoses, icd_codes):\n",
        "    \"\"\"\n",
        "    Multi-hot encodes diagnoses based on ICD codes.\n",
        "\n",
        "    Args:\n",
        "        diagnoses (str): A string representation of diagnoses (e.g., \"['I251', 'I48', 'I503']\").\n",
        "        icd_codes (tuple or list): A list or tuple of target ICD codes.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: A multi-hot encoded array.\n",
        "    \"\"\"\n",
        "    num_classes = len(icd_codes)\n",
        "    res = np.zeros(num_classes, dtype=np.float32)\n",
        "\n",
        "    # Evaluate the string as a list using ast.literal_eval\n",
        "    try:\n",
        "        diagnoses_list = ast.literal_eval(diagnoses)\n",
        "    except (SyntaxError, ValueError):\n",
        "        diagnoses_list = []  # Handle cases where evaluation fails\n",
        "\n",
        "    # Iterate through diagnoses_list and encode if it starts with any of the target codes\n",
        "    for diag in diagnoses_list:\n",
        "        for i, code in enumerate(icd_codes):  # Iterate through icd_codes with index\n",
        "            if diag.startswith(code):\n",
        "                res[i] = 1\n",
        "                break  # Exit inner loop after finding a match\n",
        "    return res"
      ],
      "metadata": {
        "id": "4cugp1DhWv2g"
      },
      "execution_count": 31,
      "outputs": [],
      "id": "4cugp1DhWv2g"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2Q3kxzOE-H-Y"
      },
      "id": "2Q3kxzOE-H-Y"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "# dataframe with 300,000 rows\n",
        "# df_full = pd.read_csv(\"src/data/label_df.csv\")\n",
        "\n",
        "# dataframe with 800,000 rows\n",
        "df_full = pd.read_csv(\"src/data/records_w_diag_icd10.csv\")\n",
        "\n",
        "\n",
        "df_full['label_train'] = df_full['all_diag_all'].apply(\n",
        "    lambda x: str(list(set([code[:3] for code in ast.literal_eval(x)])))\n",
        ")\n"
      ],
      "metadata": {
        "id": "xAZEylGAXUTH"
      },
      "execution_count": 32,
      "outputs": [],
      "id": "xAZEylGAXUTH"
    },
    {
      "cell_type": "code",
      "source": [
        "df_labels =  df_full[[\"filename\",\n",
        "            \"study_id\",\n",
        "            \"patient_id\",\n",
        "            \"ecg_time\",\n",
        "            \"label_train\",\n",
        "            \"all_diag_all\"]]\n",
        "\n",
        "target_icd_codes = (\n",
        "\"I20\", \"I21\", \"I22\", \"I23\", \"I24\", \"I25\", \"I42\", \"E87\", \"I48\", \"I44\", \"I45\", \"E11\", \"J44\", \"J45\"\n",
        ")\n",
        "\n",
        "# this is not working correctly fix this!\n",
        "df_labels['res'] = df_labels['label_train'].apply(lambda diagnoses: multihot_encode(diagnoses, target_icd_codes))\n",
        "\n",
        "# df_labels['stroke_yn'] = df_labels['res'].apply(lambda x: 1 if 1 in x else 0)\n",
        "\n",
        "df_labels = df_labels[df_labels['res'].apply(lambda x: len(x) > 0)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIC44D1p9vvQ",
        "outputId": "01db9ca3-8e1b-40dc-914b-9fdf3fd62bf8"
      },
      "id": "kIC44D1p9vvQ",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-18eb59657ac3>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_labels['res'] = df_labels['label_train'].apply(lambda diagnoses: multihot_encode(diagnoses, target_icd_codes))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Number of sparse target class"
      ],
      "metadata": {
        "id": "NLniNpIM-xzq"
      },
      "id": "NLniNpIM-xzq"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FSL0EeBhSzR2"
      },
      "id": "FSL0EeBhSzR2"
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_labels.copy()"
      ],
      "metadata": {
        "id": "kOozF8gjPV2n"
      },
      "id": "kOozF8gjPV2n",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def calculate_mean_positive_rate(df, label_col=\"res\"):\n",
        "    \"\"\"\n",
        "    Calculates the mean positive rate per label for a pandas DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The DataFrame containing the multi-hot labels.\n",
        "        label_col (str): The column name containing the multi-hot labels.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: An array containing the mean positive rate for each label.\n",
        "    \"\"\"\n",
        "\n",
        "    # Extract labels and ensure they are NumPy arrays with consistent shape\n",
        "    labels = df[label_col].apply(lambda x: np.array(x, dtype=np.float32)).values\n",
        "    labels = np.vstack(labels)  # Stack the labels into a 2D array\n",
        "\n",
        "\n",
        "    # Calculate mean positive rate per label\n",
        "    mean_positive_rate = labels.mean(axis=0)\n",
        "\n",
        "    return mean_positive_rate\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "mean_positive_rates = calculate_mean_positive_rate(df)\n",
        "\n",
        "# Print the results\n",
        "print(\"Mean positive rate per label:\", mean_positive_rates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmZetKparbjj",
        "outputId": "59d675cd-bb1d-4420-9d9a-a5d526be0093"
      },
      "id": "PmZetKparbjj",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean positive rate per label: [0.01415188 0.04707794 0.00044998 0.00050248 0.00714094 0.14026262\n",
            " 0.02158156 0.1120426  0.12146968 0.01844169 0.01022705 0.11796609\n",
            " 0.04925535 0.02839876]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_empty_labels(df, label_col=\"res\"):\n",
        "    \"\"\"\n",
        "    Counts how many samples in the DataFrame have all-zero labels.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame containing the dataset\n",
        "        label_col (str): Column name containing the multi-hot labels\n",
        "\n",
        "    Returns:\n",
        "        int: Number of rows with all-zero labels\n",
        "    \"\"\"\n",
        "    empty_count = 0\n",
        "\n",
        "    for label_str in df[label_col]:\n",
        "        if label_str.sum() == 0:\n",
        "            empty_count += 1\n",
        "\n",
        "    return empty_count\n"
      ],
      "metadata": {
        "id": "jXbW93xRpdQ0"
      },
      "id": "jXbW93xRpdQ0",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset and Model Configurations"
      ],
      "metadata": {
        "id": "afP60juTq6cc"
      },
      "id": "afP60juTq6cc"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "eaccf6f7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-10T16:44:05.670902Z",
          "start_time": "2023-07-10T16:44:05.654877Z"
        },
        "id": "eaccf6f7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "import os\n",
        "import platform\n",
        "\n",
        "# You can define ROOT_PATH somewhere above\n",
        "ROOT_PATH = \"/content/drive/MyDrive/Colab Notebooks (1)/ECG-MIMIC-main/src\"\n",
        "@dataclass\n",
        "class DatasetConfig:\n",
        "    # ECG-specific\n",
        "    NUM_LEADS:    int = 12  # 12 ECG channels (leads)\n",
        "    NUM_CLASSES:  int = 14  # 12 ICD disease codes\n",
        "    VALID_PCT:  float = 0.1\n",
        "\n",
        "    # Dataset file and folder paths\n",
        "    TRAIN_CSV:   str = os.path.join(ROOT_PATH, \"data/train.csv\")  # Your preprocessed split CSV\n",
        "    TEST_CSV:    str = os.path.join(ROOT_PATH, \"data/test.csv\")\n",
        "    MEMMAP_FILE: str = os.path.join(ROOT_PATH, \"ecg_dataset\", \"data/memmap/memmap.npy\")\n",
        "    MEMMAP_META: str = os.path.join(ROOT_PATH, \"ecg_dataset\", \"data/memmap/memmap_meta.npz\")\n",
        "\n",
        "@dataclass\n",
        "class TrainingConfig:\n",
        "    BATCH_SIZE:      int = 16\n",
        "    NUM_EPOCHS:      int = 30  # Actual training epochs\n",
        "    INIT_LR:       float = 1e-3\n",
        "    NUM_WORKERS:     int = 7\n",
        "    OPTIMIZER_NAME:  str = \"Adam\"\n",
        "    WEIGHT_DECAY:  float = 1e-4\n",
        "    USE_SCHEDULER:  bool = True\n",
        "    SCHEDULER:       str = \"multi_step_lr\"  # or \"cosine_annealing\"\n",
        "    F1_METRIC_THRESH: float = 0.5\n",
        "    FREEZE_BACKBONE: bool = False\n",
        "\n",
        "    # (Optional) model name (if you want to log it somewhere)\n",
        "    MODEL_NAME:      str = \"resnet18\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "42c43a81",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-10T16:44:07.044656Z",
          "start_time": "2023-07-10T16:44:07.029033Z"
        },
        "id": "42c43a81",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def encode_label(label: list, num_classes=10):\n",
        "    \"\"\"\n",
        "    This functions converts labels into multi-hot encoding.\n",
        "    Handles both single ICD codes and lists of codes.\n",
        "    \"\"\"\n",
        "    target = torch.zeros(num_classes)\n",
        "\n",
        "    # If label is a single code, make it a list\n",
        "    if isinstance(label, str):\n",
        "        label = [label]\n",
        "\n",
        "    for l in label:\n",
        "        # Check if 'l' contains brackets (indicating list within a string)\n",
        "        if '[' in l or ']' in l:\n",
        "            l = l.strip('[]').replace(\"'\", \"\").split(\",\")  # Handle list-like strings\n",
        "            for code in l:\n",
        "                code = code.strip()  # Remove any whitespace around code\n",
        "                if code in icd_to_index:\n",
        "                    target[icd_to_index[code]] = 1.0\n",
        "        else:\n",
        "            l = l.strip()  # Remove any whitespace around code\n",
        "            if l in icd_to_index:\n",
        "                target[icd_to_index[l]] = 1.0\n",
        "    return target\n",
        "\n",
        "\n",
        "def decode_target(\n",
        "    target: list,\n",
        "    text_labels: bool = False,\n",
        "    threshold: float = 0.4,\n",
        "    cls_labels: dict = None,\n",
        "):\n",
        "    \"\"\"This function converts the labels from\n",
        "    probablities to outputs or string representations\n",
        "    \"\"\"\n",
        "\n",
        "    result = []\n",
        "    for i, x in enumerate(target):\n",
        "        if x >= threshold:\n",
        "            if text_labels:\n",
        "                result.append(cls_labels[i] + \"(\" + str(i) + \")\")\n",
        "            else:\n",
        "                result.append(str(i))\n",
        "    return \" \".join(result)\n",
        "\n",
        "\n",
        "# This function is used for reversing the Normalization step performed\n",
        "# during image preprocessing.\n",
        "# Note the mean and std values must match the ones used.\n",
        "\n",
        "def denormalize(tensors, *, mean, std):\n",
        "    \"\"\"Denormalizes image tensors using mean and std provided\n",
        "    and clip values between 0 and 1\"\"\"\n",
        "\n",
        "    for c in range(DatasetConfig.CHANNELS):\n",
        "        tensors[:, c, :, :].mul_(std[c]).add_(mean[c])\n",
        "\n",
        "    return torch.clamp(tensors, min=0.0, max=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary mapping ICD codes to index\n",
        "# icd_to_index = {code: idx for idx, code in enumerate(target_icd_codes)}\n"
      ],
      "metadata": {
        "id": "OmWT4BbUvxAM"
      },
      "id": "OmWT4BbUvxAM",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "aEHP8HuiG06q"
      },
      "id": "aEHP8HuiG06q"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class ECGDataset(Dataset):\n",
        "    def __init__(self, dataframe, memmap, memmap_meta, normalize=True, indices=None):  # Add indices argument\n",
        "        self.df = dataframe.reset_index(drop=True)\n",
        "        self.memmap = memmap\n",
        "        self.memmap_meta = memmap_meta  # Store memmap_meta\n",
        "        self.normalize = normalize\n",
        "        self.num_classes = DatasetConfig.NUM_CLASSES\n",
        "        self.indices = indices  # Store indices if provided\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            memmap_path (str): Path to the .npy memory-mapped ECG file.\n",
        "            meta_path (str): Path to the .npz metadata file.\n",
        "        \"\"\"\n",
        "        self.starts = self.memmap_meta[\"start\"]\n",
        "        self.lengths = self.memmap_meta[\"length\"]\n",
        "        self.shape = tuple(self.memmap_meta[\"shape\"][0])\n",
        "        self.ecg_data = self.memmap.reshape(self.shape)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices) if self.indices is not None else len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the actual index from the indices list if provided\n",
        "        actual_idx = self.indices[idx] if self.indices is not None else idx\n",
        "\n",
        "        # Access starts and lengths using actual_idx\n",
        "        start_idx = self.starts[actual_idx]\n",
        "        length = self.lengths[actual_idx]\n",
        "\n",
        "        signal = self.ecg_data[start_idx:start_idx + length, :]\n",
        "\n",
        "        # Calculate mean and std for each channel (axis=0)\n",
        "        channel_means = signal.mean(axis=0)\n",
        "        channel_stds = signal.std(axis=0) + 1e-6\n",
        "\n",
        "        # Normalize across all values using channel-specific mean and std\n",
        "        signal = (signal - channel_means) / channel_stds\n",
        "\n",
        "        # Reshape to [length, 12]\n",
        "        signal = signal.T\n",
        "\n",
        "        # Convert signal to PyTorch tensor before checking for NaN/inf\n",
        "        signal = torch.tensor(signal, dtype=torch.float32)\n",
        "        label = self.df.loc[actual_idx]['res']  # shape: (length, 12)\n",
        "\n",
        "        return signal, label\n"
      ],
      "metadata": {
        "id": "lsAaJZGFleNl"
      },
      "id": "lsAaJZGFleNl",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Module"
      ],
      "metadata": {
        "id": "oll9G-J7G3GB"
      },
      "id": "oll9G-J7G3GB"
    },
    {
      "cell_type": "code",
      "source": [
        "def keep_if_multiple_labels(label_array):\n",
        "    return np.sum(label_array) >= 1"
      ],
      "metadata": {
        "id": "HVmEJkotC718"
      },
      "id": "HVmEJkotC718",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U imbalanced-learn"
      ],
      "metadata": {
        "id": "od6nM-zALNK8",
        "outputId": "c52973de-729d-4feb-ac00-868585d2bb41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "od6nM-zALNK8",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: numpy<3,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.15.2)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler, SMOTE"
      ],
      "metadata": {
        "id": "PggLcHZTLPn-"
      },
      "id": "PggLcHZTLPn-",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "id": "0d6a7838",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-10T16:44:07.092291Z",
          "start_time": "2023-07-10T16:44:07.060054Z"
        },
        "id": "0d6a7838",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold, MultilabelStratifiedShuffleSplit\n",
        "\n",
        "class ECGDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, dataframe, memmap_meta, memmap, batch_size, num_workers, pin_memory, valid_pct, label_filter_fn = keep_if_multiple_labels , normalize=True, shuffle_validation=False):\n",
        "        \"\"\"\n",
        "        :param dataframe: Original unfiltered dataframe.\n",
        "        :param label_filter_fn: A function that takes a label array and returns True/False to filter sparse labels.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.original_df = dataframe\n",
        "        self.memmap_meta = memmap_meta\n",
        "        self.memmap = memmap\n",
        "        self.normalize = normalize\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        self.pin_memory = pin_memory\n",
        "        self.valid_pct = valid_pct\n",
        "        self.shuffle_validation = shuffle_validation\n",
        "        self.label_filter_fn = label_filter_fn\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        label_col = 'res'\n",
        "        np.random.seed(42)\n",
        "\n",
        "        # Parse and convert labels\n",
        "        df = self.original_df.copy()\n",
        "        df[label_col] = df[label_col].apply(lambda x: np.fromstring(x[1:-1], dtype=float, sep=' ') if isinstance(x, str) else x)\n",
        "\n",
        "        # --- Step 1: Filter sparse labels ---\n",
        "        mask = df[label_col].apply(self.label_filter_fn)\n",
        "        df_filtered = df[mask].reset_index(drop=False)  # Keep original indices for alignment\n",
        "        self.filtered_df = df_filtered  # Save for debugging\n",
        "\n",
        "        # --- Step 2: Prepare Y matrix ---\n",
        "        Y = np.vstack(df_filtered[label_col].values)\n",
        "\n",
        "        # --- Step 3: Stratified split ---\n",
        "        splitter = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "        train_val_idx, test_idx = next(splitter.split(df_filtered, Y))\n",
        "\n",
        "        # Second stratified split for validation\n",
        "        splitter_val = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=self.valid_pct, random_state=42)\n",
        "        Y_train_val = Y[train_val_idx]\n",
        "        train_idx, val_idx = next(splitter_val.split(df_filtered.iloc[train_val_idx], Y_train_val))\n",
        "\n",
        "        # Map back to original indices for memmap alignment\n",
        "        self.train_idx = df_filtered.iloc[train_val_idx].iloc[train_idx]['index'].to_numpy()\n",
        "        self.val_idx = df_filtered.iloc[train_val_idx].iloc[val_idx]['index'].to_numpy()\n",
        "        self.test_idx = df_filtered.iloc[test_idx]['index'].to_numpy()\n",
        "\n",
        "        # --- Step 4: Build datasets ---\n",
        "        self.train_ds = ECGDataset(\n",
        "            dataframe=self.original_df,  # full dataframe\n",
        "            memmap=self.memmap,\n",
        "            memmap_meta=self.memmap_meta,\n",
        "            normalize=self.normalize,\n",
        "            indices=self.train_idx,\n",
        "        )\n",
        "        self.valid_ds = ECGDataset(\n",
        "            dataframe=self.original_df,\n",
        "            memmap=self.memmap,\n",
        "            memmap_meta=self.memmap_meta,\n",
        "            normalize=self.normalize,\n",
        "            indices=self.val_idx,\n",
        "        )\n",
        "        self.test_ds = ECGDataset(\n",
        "            dataframe=self.original_df,\n",
        "            memmap=self.memmap,\n",
        "            memmap_meta=self.memmap_meta,\n",
        "            normalize=self.normalize,\n",
        "            indices=self.test_idx,\n",
        "        )\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_ds,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=self.num_workers,\n",
        "            pin_memory=self.pin_memory,\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.valid_ds,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=self.shuffle_validation,\n",
        "            num_workers=self.num_workers,\n",
        "            pin_memory=self.pin_memory,\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_ds,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=self.num_workers,\n",
        "            pin_memory=self.pin_memory,\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "id": "91ee71b8",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2023-07-10T16:43:46.064Z"
        },
        "id": "91ee71b8"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "\n",
        "def get_model(model_name: str, num_classes: int, freeze_backbone: bool= True):\n",
        "    \"\"\"A helper function to load and prepare any classification model\n",
        "    available in Torchvision for transfer learning or fine-tuning.\"\"\"\n",
        "\n",
        "    model = getattr(torchvision.models, model_name)(weights=\"DEFAULT\")\n",
        "\n",
        "    if freeze_backbone:\n",
        "        # Set all layer to be non-trainable\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    model_childrens = [name for name, _ in model.named_children()]\n",
        "\n",
        "    try:\n",
        "        final_layer_in_features = getattr(model, f\"{model_childrens[-1]}\")[-1].in_features\n",
        "    except Exception as e:\n",
        "        final_layer_in_features = getattr(model, f\"{model_childrens[-1]}\").in_features\n",
        "\n",
        "    new_output_layer = nn.Linear(\n",
        "        in_features=final_layer_in_features,\n",
        "        out_features=num_classes\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        getattr(model, f\"{model_childrens[-1]}\")[-1] = new_output_layer\n",
        "    except:\n",
        "        setattr(model, model_childrens[-1], new_output_layer)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f953896",
      "metadata": {
        "id": "3f953896"
      },
      "source": [
        "**Function usage example:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcT1fLY8wZVc",
        "outputId": "072fb778-2ccb-4b96-92ef-7d4b39153d52"
      },
      "id": "qcT1fLY8wZVc",
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (1.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "id": "3696a2b6",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2023-07-10T16:43:46.070Z"
        },
        "id": "3696a2b6"
      },
      "outputs": [],
      "source": [
        "# from torchinfo import summary\n",
        "# import torch.nn as nn\n",
        "\n",
        "# # Suppose your ECG signals are 1000 time steps long\n",
        "# TIME_LENGTH = 1000\n",
        "\n",
        "# model = get_model(\n",
        "#     model_name=TrainingConfig.MODEL_NAME,    # Should be \"resnet50\"\n",
        "#     num_classes=DatasetConfig.NUM_CLASSES,\n",
        "#     freeze_backbone=False,\n",
        "# )\n",
        "\n",
        "# # Correctly modify the first convolutional layer to accept 12 channels\n",
        "# model.conv1 = nn.Conv2d(in_channels=12, out_channels=64, kernel_size=(7, 1), stride=(2, 1), padding=(3, 0), bias=False) # Reassign the layer\n",
        "\n",
        "# # Proper ECG input shape\n",
        "# summary(\n",
        "#     model,\n",
        "#     input_size=(TrainingConfig.BATCH_SIZE, DatasetConfig.NUM_LEADS, TIME_LENGTH, 1),  # (batch, channels=12, time, width=1)\n",
        "#     depth=2,\n",
        "#     device=\"cpu\",\n",
        "#     col_names=[\"output_size\", \"num_params\", \"trainable\"]\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Assuming 'df' is your DataFrame and 'res' is the column with labels\n",
        "# class_frequencies = []\n",
        "# for code in target_icd_codes:\n",
        "#     # Count occurrences of the current code in the 'res' column\n",
        "#     freq = df['res'].str.contains(code).sum()\n",
        "#     class_frequencies.append(freq)\n",
        "\n",
        "# # Convert the list to a PyTorch tensor\n",
        "# class_frequencies = torch.tensor(class_frequencies, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "yJudCyPyPuV5"
      },
      "id": "yJudCyPyPuV5",
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "BOn3XvNs8bqV"
      },
      "id": "BOn3XvNs8bqV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyK98BI28ky0"
      },
      "source": [
        "## Simple LSTM Model"
      ],
      "id": "dyK98BI28ky0"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "import torch.nn.functional as F\n",
        "from torchmetrics.classification import MultilabelAccuracy, MultilabelF1Score, MultilabelAUROC\n",
        "\n",
        "class LSTMClassifier(pl.LightningModule):\n",
        "    def __init__(self, input_size=12, hidden_size=64, num_layers=2, num_classes=2, lr=1e-3, f1_metric_threshold=0.5):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True  # Using bidirectional LSTM\n",
        "        )\n",
        "\n",
        "        # Multi-label output layer\n",
        "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
        "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
        "        self.lr = lr\n",
        "\n",
        "        # Metrics\n",
        "        self.train_acc = MultilabelAccuracy(num_labels=num_classes, threshold=f1_metric_threshold)\n",
        "        self.train_f1 = MultilabelF1Score(num_labels=num_classes, average=\"macro\", threshold=f1_metric_threshold)\n",
        "        self.train_auc = MultilabelAUROC(num_labels=num_classes)\n",
        "\n",
        "        self.val_acc = MultilabelAccuracy(num_labels=num_classes, threshold=f1_metric_threshold)\n",
        "        self.val_f1 = MultilabelF1Score(num_labels=num_classes, average=\"macro\", threshold=f1_metric_threshold)\n",
        "        self.val_auc = MultilabelAUROC(num_labels=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Adjust the input shape to match LSTM requirements\n",
        "        x = x.permute(0, 2, 1)  # Permute to (batch_size, sequence_length, input_size)\n",
        "\n",
        "        # Ensure input data type is float32\n",
        "        x = x.type(torch.float32)\n",
        "\n",
        "        # Pass the modified input to the LSTM\n",
        "        out, _ = self.lstm(x)\n",
        "\n",
        "        out = out[:, -1, :]  # Take the last hidden state\n",
        "        logits = self.fc(out)\n",
        "        return logits\n",
        "    # def on_train_start(self):\n",
        "    #     # Log model type as a parameter or tag\n",
        "    #     mlflow.pytorch.log_model(self, \"model\") # Registers the model\n",
        "    #     mlflow.log_param(\"model_type\", \"LSTM\")  # Log as parameter\n",
        "    #     mlflow.set_tag(\"model_type\", \"LSTM\")\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.loss_fn(logits, y.float())\n",
        "        probs = torch.sigmoid(logits)\n",
        "\n",
        "        acc = self.train_acc(probs, y.int())\n",
        "        f1 = self.train_f1(probs, y.int())\n",
        "        auc = self.train_auc(probs, y.int())\n",
        "\n",
        "        self.log(\"train_loss\", loss, prog_bar=True)\n",
        "        self.log(\"train_acc\", acc, prog_bar=True)\n",
        "        self.log(\"train_f1\", f1, prog_bar=True)\n",
        "        self.log(\"train_auc\", auc, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.loss_fn(logits, y.float())\n",
        "        probs = torch.sigmoid(logits)\n",
        "\n",
        "        acc = self.val_acc(probs, y.int())\n",
        "        f1 = self.val_f1(probs, y.int())\n",
        "        auc = self.val_auc(probs, y.int())\n",
        "\n",
        "        self.log(\"val_loss\", loss, prog_bar=True)\n",
        "        self.log(\"val_acc\", acc, prog_bar=True)\n",
        "        self.log(\"val_f1\", f1, prog_bar=True)\n",
        "        self.log(\"val_auc\", auc, prog_bar=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n"
      ],
      "metadata": {
        "id": "C6j_HQhvobr4"
      },
      "execution_count": 141,
      "outputs": [],
      "id": "C6j_HQhvobr4"
    },
    {
      "source": [
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "\n",
        "class Swish(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(x)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "p7AO6C9-8TkZ"
      },
      "execution_count": 142,
      "outputs": [],
      "id": "p7AO6C9-8TkZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN-Attention model"
      ],
      "metadata": {
        "id": "fOIc92Pq7LU7"
      },
      "id": "fOIc92Pq7LU7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ConvNormPool"
      ],
      "metadata": {
        "id": "e8spFZLq7ccJ"
      },
      "id": "e8spFZLq7ccJ"
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNormPool(pl.LightningModule):\n",
        "    \"\"\"Conv Skip-connection module\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size,\n",
        "        hidden_size,\n",
        "        kernel_size,\n",
        "        norm_type='bachnorm'\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.kernel_size = kernel_size\n",
        "        self.conv_1 = nn.Conv1d(\n",
        "            in_channels=input_size,\n",
        "            out_channels=hidden_size,\n",
        "            kernel_size=kernel_size\n",
        "        )\n",
        "        self.conv_2 = nn.Conv1d(\n",
        "            in_channels=hidden_size,\n",
        "            out_channels=hidden_size,\n",
        "            kernel_size=kernel_size\n",
        "        )\n",
        "        self.conv_3 = nn.Conv1d(\n",
        "            in_channels=hidden_size,\n",
        "            out_channels=hidden_size,\n",
        "            kernel_size=kernel_size\n",
        "        )\n",
        "        self.swish_1 = Swish()\n",
        "        self.swish_2 = Swish()\n",
        "        self.swish_3 = Swish()\n",
        "        if norm_type == 'group':\n",
        "            self.normalization_1 = nn.GroupNorm(\n",
        "                num_groups=8,\n",
        "                num_channels=hidden_size\n",
        "            )\n",
        "            self.normalization_2 = nn.GroupNorm(\n",
        "                num_groups=8,\n",
        "                num_channels=hidden_size\n",
        "            )\n",
        "            self.normalization_3 = nn.GroupNorm(\n",
        "                num_groups=8,\n",
        "                num_channels=hidden_size\n",
        "            )\n",
        "        else:\n",
        "            self.normalization_1 = nn.BatchNorm1d(num_features=hidden_size)\n",
        "            self.normalization_2 = nn.BatchNorm1d(num_features=hidden_size)\n",
        "            self.normalization_3 = nn.BatchNorm1d(num_features=hidden_size)\n",
        "\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
        "\n",
        "    def forward(self, input):\n",
        "        conv1 = self.conv_1(input)\n",
        "        x = self.normalization_1(conv1)\n",
        "        x = self.swish_1(x)\n",
        "        x = F.pad(x, pad=(self.kernel_size - 1, 0))\n",
        "\n",
        "        x = self.conv_2(x)\n",
        "        x = self.normalization_2(x)\n",
        "        x = self.swish_2(x)\n",
        "        x = F.pad(x, pad=(self.kernel_size - 1, 0))\n",
        "\n",
        "        conv3 = self.conv_3(x)\n",
        "        x = self.normalization_3(conv1+conv3)\n",
        "        x = self.swish_3(x)\n",
        "        x = F.pad(x, pad=(self.kernel_size - 1, 0))\n",
        "\n",
        "        x = self.pool(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "NPtpv9_j6Ywv"
      },
      "execution_count": 143,
      "outputs": [],
      "id": "NPtpv9_j6Ywv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN"
      ],
      "metadata": {
        "id": "M7itc5Nq7fCM"
      },
      "id": "M7itc5Nq7fCM"
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(pl.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size = 1,\n",
        "        hid_size = 256,\n",
        "        kernel_size = 5,\n",
        "        num_classes = 5,\n",
        "    ):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = ConvNormPool(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hid_size,\n",
        "            kernel_size=kernel_size,\n",
        "        )\n",
        "        self.conv2 = ConvNormPool(\n",
        "            input_size=hid_size,\n",
        "            hidden_size=hid_size//2,\n",
        "            kernel_size=kernel_size,\n",
        "        )\n",
        "        self.conv3 = ConvNormPool(\n",
        "            input_size=hid_size//2,\n",
        "            hidden_size=hid_size//4,\n",
        "            kernel_size=kernel_size,\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool1d((1))\n",
        "        self.fc = nn.Linear(in_features=hid_size//4, out_features=num_classes)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.conv1(input)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.avgpool(x)\n",
        "        # print(x.shape) # num_features * num_channels\n",
        "        x = x.view(-1, x.size(1) * x.size(2))\n",
        "        x = F.softmax(self.fc(x), dim=1)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "_HLYf3RW6hNe"
      },
      "execution_count": 144,
      "outputs": [],
      "id": "_HLYf3RW6hNe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN"
      ],
      "metadata": {
        "id": "BjoJ234gFYOa"
      },
      "id": "BjoJ234gFYOa"
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(pl.LightningModule):\n",
        "    \"\"\"RNN module(cell type lstm or gru)\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size,\n",
        "        hid_size,\n",
        "        num_rnn_layers=1,\n",
        "        dropout_p = 0.2,\n",
        "        bidirectional = False,\n",
        "        rnn_type = 'lstm',\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        if rnn_type == 'lstm':\n",
        "            self.rnn_layer = nn.LSTM(\n",
        "                input_size=input_size,\n",
        "                hidden_size=hid_size,\n",
        "                num_layers=num_rnn_layers,\n",
        "                dropout=dropout_p if num_rnn_layers>1 else 0,\n",
        "                bidirectional=bidirectional,\n",
        "                batch_first=True,\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            self.rnn_layer = nn.GRU(\n",
        "                input_size=input_size,\n",
        "                hidden_size=hid_size,\n",
        "                num_layers=num_rnn_layers,\n",
        "                dropout=dropout_p if num_rnn_layers>1 else 0,\n",
        "                bidirectional=bidirectional,\n",
        "                batch_first=True,\n",
        "            )\n",
        "    def forward(self, input):\n",
        "        outputs, hidden_states = self.rnn_layer(input)\n",
        "        return outputs, hidden_states\n"
      ],
      "metadata": {
        "id": "OHzkyOyw74yI"
      },
      "execution_count": 145,
      "outputs": [],
      "id": "OHzkyOyw74yI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN Model"
      ],
      "metadata": {
        "id": "f2fFMO5j7ijR"
      },
      "id": "f2fFMO5j7ijR"
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNModel(pl.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size,\n",
        "        hid_size,\n",
        "        rnn_type,\n",
        "        bidirectional,\n",
        "        n_classes=5,\n",
        "        kernel_size=5,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.rnn_layer = RNN(\n",
        "            input_size=46,#hid_size * 2 if bidirectional else hid_size,\n",
        "            hid_size=hid_size,\n",
        "            rnn_type=rnn_type,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "        self.conv1 = ConvNormPool(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hid_size,\n",
        "            kernel_size=kernel_size,\n",
        "        )\n",
        "        self.conv2 = ConvNormPool(\n",
        "            input_size=hid_size,\n",
        "            hidden_size=hid_size,\n",
        "            kernel_size=kernel_size,\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool1d((1))\n",
        "        self.fc = nn.Linear(in_features=hid_size, out_features=n_classes)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.conv1(input)\n",
        "        x = self.conv2(x)\n",
        "        x, _ = self.rnn_layer(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(-1, x.size(1) * x.size(2))\n",
        "        x = F.sigmoid(self.fc(x), dim=1)#.squeeze(1)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "bbaUcwi-6j6A"
      },
      "execution_count": 146,
      "outputs": [],
      "id": "bbaUcwi-6j6A"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN Attention Model"
      ],
      "metadata": {
        "id": "dXKYZVjn9Zrk"
      },
      "id": "dXKYZVjn9Zrk"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def calculate_class_weights(df, label_col=\"res\"):\n",
        "    \"\"\"\n",
        "    Calculates class weights based on label frequencies.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The DataFrame containing the multi-hot labels.\n",
        "        label_col (str): The column name containing the multi-hot labels.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: A tensor containing the class weights.\n",
        "    \"\"\"\n",
        "    label_counts = df[label_col].sum()  # Assuming 'res' is the column with multi-hot labels\n",
        "    num_samples = len(df)\n",
        "    class_weights = num_samples / (df.shape[1] * label_counts)\n",
        "    return torch.tensor(class_weights, dtype=torch.float32) # Move to the same device as your model\n",
        "\n",
        "# Assuming 'training_df' is your training DataFrame:\n",
        "class_weights = calculate_class_weights(df)"
      ],
      "metadata": {
        "id": "JDEfvgIkILFp"
      },
      "id": "JDEfvgIkILFp",
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pytorch_lightning as pl\n",
        "from torchmetrics.classification import MultilabelAccuracy, MultilabelF1Score, MultilabelAUROC\n",
        "\n",
        "class RNNAttentionModel(pl.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        hid_size =64,\n",
        "        rnn_type = 'lstm',\n",
        "        bidirectional=False,\n",
        "        num_classes=DatasetConfig.NUM_CLASSES,\n",
        "        input_size =12,\n",
        "        kernel_size=5,\n",
        "        lr=1e-3,\n",
        "        f1_metric_threshold=0.5,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.conv1 = ConvNormPool(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hid_size,\n",
        "            kernel_size=kernel_size,\n",
        "        )\n",
        "        self.conv2 = ConvNormPool(\n",
        "            input_size=hid_size,\n",
        "            hidden_size=hid_size,\n",
        "            kernel_size=kernel_size,\n",
        "        )\n",
        "\n",
        "        self.rnn_layer = RNN(\n",
        "            input_size=hid_size,\n",
        "            hid_size=hid_size,\n",
        "            rnn_type=rnn_type,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "\n",
        "        self.attn = nn.Linear(hid_size, hid_size, bias=False)\n",
        "        self.fc = nn.Linear(in_features=hid_size, out_features=num_classes)  # Multi-label output\n",
        "        self.loss_fn = nn.BCEWithLogitsLoss(pos_weight=class_weights)\n",
        "        self.lr = lr\n",
        "\n",
        "        # Metrics\n",
        "        self.train_acc = MultilabelAccuracy(num_labels=num_classes, threshold=f1_metric_threshold)\n",
        "        self.train_f1 = MultilabelF1Score(num_labels=num_classes, average=\"macro\", threshold=f1_metric_threshold)\n",
        "        self.train_auc = MultilabelAUROC(num_labels=num_classes)\n",
        "\n",
        "        self.val_acc = MultilabelAccuracy(num_labels=num_classes, threshold=f1_metric_threshold)\n",
        "        self.val_f1 = MultilabelF1Score(num_labels=num_classes, average=\"macro\", threshold=f1_metric_threshold)\n",
        "        self.val_auc = MultilabelAUROC(num_labels=num_classes)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # input = input.permute(0, 2, 1)  # Remove this line - permutation is done in the dataset\n",
        "        x = self.conv1(input)\n",
        "        x = self.conv2(x)\n",
        "        x = x.permute(0, 2, 1)  # Permute before the RNN layer\n",
        "\n",
        "        x_out, _ = self.rnn_layer(x)\n",
        "\n",
        "        attn_weights = torch.softmax(self.attn(x_out), dim=1)\n",
        "        x = torch.sum(attn_weights * x_out, dim=1)\n",
        "\n",
        "        logits = self.fc(x)\n",
        "        return logits\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.loss_fn(logits, y.float())\n",
        "        probs = torch.sigmoid(logits)\n",
        "\n",
        "        acc = self.train_acc(probs, y.int())\n",
        "        f1 = self.train_f1(probs, y.int())\n",
        "        auc = self.train_auc(probs, y.int())\n",
        "\n",
        "        self.log(\"train_loss\", loss, prog_bar=True)\n",
        "        self.log(\"train_acc\", acc, prog_bar=True)\n",
        "        self.log(\"train_f1\", f1, prog_bar=True)\n",
        "        self.log(\"train_auc\", auc, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.loss_fn(logits, y.float())\n",
        "        probs = torch.sigmoid(logits)\n",
        "\n",
        "        acc = self.val_acc(probs, y.int())\n",
        "        f1 = self.val_f1(probs, y.int())\n",
        "        auc = self.val_auc(probs, y.int())\n",
        "\n",
        "        self.log(\"val_loss\", loss, prog_bar=True)\n",
        "        self.log(\"val_acc\", acc, prog_bar=True)\n",
        "        self.log(\"val_f1\", f1, prog_bar=True)\n",
        "        self.log(\"val_auc\", auc, prog_bar=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=self.lr)"
      ],
      "metadata": {
        "id": "-1pz8ZdK9d-1"
      },
      "execution_count": 148,
      "outputs": [],
      "id": "-1pz8ZdK9d-1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Initialization"
      ],
      "metadata": {
        "id": "gdZWRSKrG_EA"
      },
      "id": "gdZWRSKrG_EA"
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "id": "ee9cff32-b77e-4fc6-8cde-c9d67b431263",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2023-07-10T16:43:46.083Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee9cff32-b77e-4fc6-8cde-c9d67b431263",
        "outputId": "56398002-f115-409e-e0a6-7fbdc0c89a56",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n"
          ]
        }
      ],
      "source": [
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
        "\n",
        "# 1. Seed everything for reproducibility\n",
        "pl.seed_everything(42, workers=True)\n",
        "\n",
        "memmap_path = \"src/data/memmap/memmap.npy\"\n",
        "\n",
        "memmap_data = np.memmap(memmap_path, dtype=np.float32, mode='r')\n",
        "memmap_meta_path = \"src/data/memmap/memmap_meta.npz\"\n",
        "memmap_meta = np.load(memmap_meta_path, allow_pickle=True)\n",
        "# Instantiate the ECGDataModule\n",
        "dm = ECGDataModule(\n",
        "    dataframe=df,            # Your loaded DataFrame\n",
        "    memmap=memmap_data,             # Your loaded memmap\n",
        "    memmap_meta = memmap_meta,\n",
        "    batch_size=TrainingConfig.BATCH_SIZE,\n",
        "    num_workers=TrainingConfig.NUM_WORKERS,\n",
        "    pin_memory=torch.cuda.is_available(),\n",
        "    valid_pct=DatasetConfig.VALID_PCT,\n",
        ")\n",
        "\n",
        "# Prepare data (nothing to download for ECG, so will pass)\n",
        "dm.prepare_data()\n",
        "\n",
        "# Split dataset into training and validation sets\n",
        "dm.setup()\n",
        "\n",
        "# 4. Create ModelCheckpoint callback\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    monitor=\"valid/f1\",        # Monitor validation F1 score\n",
        "    mode=\"max\",                # Maximize F1\n",
        "    filename=\"ecg_epoch{epoch:03d}_vloss{valid/loss:.4f}_vf1{valid/f1:.4f}\",\n",
        "    auto_insert_metric_name=False,\n",
        "    save_top_k=1,              # Save the best model only\n",
        ")\n",
        "\n",
        "# 5. Create Learning Rate Monitor callback\n",
        "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "id": "fed847ae-7330-43f3-90fa-85bbd10f498f",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2023-07-10T16:43:46.088Z"
        },
        "id": "fed847ae-7330-43f3-90fa-85bbd10f498f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# # To reload tensorBoard\n",
        "# %reload_ext tensorboard\n",
        "\n",
        "# # logs folder path\n",
        "# %tensorboard --logdir=lightning_logs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83c7a942",
      "metadata": {
        "id": "83c7a942"
      },
      "source": [
        "**Train**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset checking before running model"
      ],
      "metadata": {
        "id": "z-RQCoehJ6mz"
      },
      "id": "z-RQCoehJ6mz"
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming dm is your ECGDataModule instance\n",
        "training_df = dm.filtered_df\n",
        "\n",
        "# Inspect the shape\n",
        "print(\"Shape of training DataFrame:\", training_df.shape)\n"
      ],
      "metadata": {
        "id": "0zv1qYEQpOUo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f64c3d27-f17f-4957-e929-f9b0c43d0a4f"
      },
      "id": "0zv1qYEQpOUo",
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training DataFrame: (241537, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_positive_rates = calculate_mean_positive_rate(training_df)\n",
        "\n",
        "# Print the results\n",
        "print(\"Mean positive rate per label:\", mean_positive_rates)"
      ],
      "metadata": {
        "id": "goJjH57ZyJZ0",
        "outputId": "14464d00-0fe7-4821-8b6d-39d253a74db4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "goJjH57ZyJZ0",
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean positive rate per label: [0.04687481 0.1559347  0.00149045 0.00166434 0.02365269 0.4645872\n",
            " 0.07148387 0.371115   0.40234002 0.06108381 0.03387473 0.39073518\n",
            " 0.16314685 0.09406427]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "B_KsibxBZorA"
      },
      "id": "B_KsibxBZorA"
    },
    {
      "cell_type": "code",
      "source": [
        "# # Assuming 'dm' is your ECGDataModule instance\n",
        "# train_loader = dm.train_dataloader()\n",
        "\n",
        "# # 1. Using len() on the dataloader:\n",
        "# num_batches = len(train_loader)\n",
        "# print(f\"Number of batches in train_dataloader: {num_batches}\")\n",
        "\n",
        "# # 2. Calculating total samples from batch size and num_batches:\n",
        "# total_samples = num_batches * train_loader.batch_size\n",
        "# print(f\"Estimated total samples in training dataset: {total_samples}\")\n",
        "\n",
        "# # 3. Accessing the underlying dataset directly (more accurate):\n",
        "# total_samples_accurate = len(train_loader.dataset)\n",
        "# print(f\"Actual total samples in training dataset: {total_samples_accurate}\")\n"
      ],
      "metadata": {
        "id": "CRUY44K5yODQ"
      },
      "id": "CRUY44K5yODQ",
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNNAttentionModel()\n",
        "# model = LSTMClassifier()"
      ],
      "metadata": {
        "id": "5v4bo0sE4jXl"
      },
      "id": "5v4bo0sE4jXl",
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "TIME_LENGTH = 1000\n",
        "\n",
        "summary(\n",
        "    model,\n",
        "    input_size=(TrainingConfig.BATCH_SIZE, DatasetConfig.NUM_LEADS, TIME_LENGTH),  # (batch, channels=12, time, width=1)\n",
        "    depth=2,\n",
        "    device=\"cpu\",\n",
        "    col_names=[\"output_size\", \"num_params\", \"trainable\"]\n",
        ")"
      ],
      "metadata": {
        "id": "Km4aQkHHyW-g",
        "outputId": "3f954e25-c774-43ae-cfd9-0cc848b13b91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Km4aQkHHyW-g",
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===================================================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #                   Trainable\n",
              "===================================================================================================================\n",
              "RNNAttentionModel                        [16, 14]                  --                        True\n",
              "ConvNormPool: 1-1                      [16, 64, 500]             --                        True\n",
              "    Conv1d: 2-1                       [16, 64, 996]             3,904                     True\n",
              "    BatchNorm1d: 2-2                  [16, 64, 996]             128                       True\n",
              "    Swish: 2-3                        [16, 64, 996]             --                        --\n",
              "    Conv1d: 2-4                       [16, 64, 996]             20,544                    True\n",
              "    BatchNorm1d: 2-5                  [16, 64, 996]             128                       True\n",
              "    Swish: 2-6                        [16, 64, 996]             --                        --\n",
              "    Conv1d: 2-7                       [16, 64, 996]             20,544                    True\n",
              "    BatchNorm1d: 2-8                  [16, 64, 996]             128                       True\n",
              "    Swish: 2-9                        [16, 64, 996]             --                        --\n",
              "    MaxPool1d: 2-10                   [16, 64, 500]             --                        --\n",
              "ConvNormPool: 1-2                      [16, 64, 250]             --                        True\n",
              "    Conv1d: 2-11                      [16, 64, 496]             20,544                    True\n",
              "    BatchNorm1d: 2-12                 [16, 64, 496]             128                       True\n",
              "    Swish: 2-13                       [16, 64, 496]             --                        --\n",
              "    Conv1d: 2-14                      [16, 64, 496]             20,544                    True\n",
              "    BatchNorm1d: 2-15                 [16, 64, 496]             128                       True\n",
              "    Swish: 2-16                       [16, 64, 496]             --                        --\n",
              "    Conv1d: 2-17                      [16, 64, 496]             20,544                    True\n",
              "    BatchNorm1d: 2-18                 [16, 64, 496]             128                       True\n",
              "    Swish: 2-19                       [16, 64, 496]             --                        --\n",
              "    MaxPool1d: 2-20                   [16, 64, 250]             --                        --\n",
              "RNN: 1-3                               [16, 250, 64]             --                        True\n",
              "    LSTM: 2-21                        [16, 250, 64]             33,280                    True\n",
              "Linear: 1-4                            [16, 250, 64]             4,096                     True\n",
              "Linear: 1-5                            [16, 14]                  910                       True\n",
              "===================================================================================================================\n",
              "Total params: 145,678\n",
              "Trainable params: 145,678\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.GIGABYTES): 1.34\n",
              "===================================================================================================================\n",
              "Input size (MB): 0.77\n",
              "Forward/backward pass size (MB): 77.43\n",
              "Params size (MB): 0.58\n",
              "Estimated Total Size (MB): 78.78\n",
              "==================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "909e0f0d",
      "metadata": {
        "id": "909e0f0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212,
          "referenced_widgets": [
            "cfda115cd471477f8035ba5efb1b80c9",
            "298614e99e394d57b3291e51e79564fb",
            "f3946984ec7246e791c356d1f17aca6c",
            "68cc8d891acf486eb4820fcb76c36c33",
            "ba937e60907940ee9c4214941d3adb38",
            "ef7e852f17cd46c9b16fc8d3fbc1ced9",
            "f8797100c63d4ffd9b2152ff51f94e46",
            "9d196314153d4a6f9b1e0992df49998c",
            "ea9afa53af35478ebc4953d494e67983",
            "a80ce51d0044406b85a1e7be0f3e0e22",
            "0ea7446d57b54f68b8e5e7347bfa6372",
            "772c7be956e144d7ac6c344bb3610d18",
            "0ae43c7a4b3e4b8c8e5e3f14b622a3e0",
            "48c1c40395384895b10d969a28edff82",
            "72cbc5dd1bee4b15964e2d672d0fd3ac",
            "fd294fe7416b489ebf8d6ad271a5bf6e",
            "61ec07a4eb03466bbb4a4bcb9a52a068",
            "6f5b904caec44e9d8a9935490f1c973b",
            "af2524c0cf91456fb00d584aca7a5a7b",
            "95215cd203944893bc42a6e978036c1c",
            "e07bf838c4244e808e7b6d09254c9ef6",
            "baf745498197497c915d8bedf46891a8"
          ]
        },
        "outputId": "96782610-e85d-4714-c6a4-82dabd424fd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightning_fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfda115cd471477f8035ba5efb1b80c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
            "  warnings.warn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "772c7be956e144d7ac6c344bb3610d18"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Initializing the Trainer class object.\n",
        "# It uses 'Tensorboard' as its default logger.\n",
        "trainer = pl.Trainer(\n",
        "    accelerator=\"auto\", # Auto select the best hardware accelerator available\n",
        "    devices=\"auto\", # Auto select available devices for the accelerator (For eg. mutiple GPUs)\n",
        "    strategy=\"auto\", # Auto select the distributed training strategy.\n",
        "    max_epochs=1, # Maximum number of epoch to train for.\n",
        "    deterministic=True, # For deteministic and reproducible training.\n",
        "    enable_model_summary=False, # Disable printing of model summary as we are using torchinfo.\n",
        "    callbacks=[model_checkpoint, lr_monitor],  # Declaring callbacks to use.\n",
        "    precision=\"16\", # Using Mixed Precision training.\n",
        "    logger=True, # Auto generate TensorBoard logs.\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.fit(model, dm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7714dd0f-502c-4297-ad13-a24655ca7c5d",
      "metadata": {
        "id": "7714dd0f-502c-4297-ad13-a24655ca7c5d"
      },
      "source": [
        "## 7 Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa9333e2",
      "metadata": {
        "id": "fa9333e2"
      },
      "source": [
        "To perform inference, first, we need to load the best checkpoint saved during training. We can do it simply by executing the following:"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "379.387px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cfda115cd471477f8035ba5efb1b80c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_298614e99e394d57b3291e51e79564fb",
              "IPY_MODEL_f3946984ec7246e791c356d1f17aca6c",
              "IPY_MODEL_68cc8d891acf486eb4820fcb76c36c33"
            ],
            "layout": "IPY_MODEL_ba937e60907940ee9c4214941d3adb38"
          }
        },
        "298614e99e394d57b3291e51e79564fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef7e852f17cd46c9b16fc8d3fbc1ced9",
            "placeholder": "",
            "style": "IPY_MODEL_f8797100c63d4ffd9b2152ff51f94e46",
            "value": "SanityCheckingDataLoader0:100%"
          }
        },
        "f3946984ec7246e791c356d1f17aca6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d196314153d4a6f9b1e0992df49998c",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea9afa53af35478ebc4953d494e67983",
            "value": 2
          }
        },
        "68cc8d891acf486eb4820fcb76c36c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a80ce51d0044406b85a1e7be0f3e0e22",
            "placeholder": "",
            "style": "IPY_MODEL_0ea7446d57b54f68b8e5e7347bfa6372",
            "value": "2/2[00:00&lt;00:00,27.85it/s]"
          }
        },
        "ba937e60907940ee9c4214941d3adb38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "ef7e852f17cd46c9b16fc8d3fbc1ced9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8797100c63d4ffd9b2152ff51f94e46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d196314153d4a6f9b1e0992df49998c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea9afa53af35478ebc4953d494e67983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a80ce51d0044406b85a1e7be0f3e0e22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ea7446d57b54f68b8e5e7347bfa6372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "772c7be956e144d7ac6c344bb3610d18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ae43c7a4b3e4b8c8e5e3f14b622a3e0",
              "IPY_MODEL_48c1c40395384895b10d969a28edff82",
              "IPY_MODEL_72cbc5dd1bee4b15964e2d672d0fd3ac"
            ],
            "layout": "IPY_MODEL_fd294fe7416b489ebf8d6ad271a5bf6e"
          }
        },
        "0ae43c7a4b3e4b8c8e5e3f14b622a3e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61ec07a4eb03466bbb4a4bcb9a52a068",
            "placeholder": "",
            "style": "IPY_MODEL_6f5b904caec44e9d8a9935490f1c973b",
            "value": "Epoch0:0%"
          }
        },
        "48c1c40395384895b10d969a28edff82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af2524c0cf91456fb00d584aca7a5a7b",
            "max": 10874,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95215cd203944893bc42a6e978036c1c",
            "value": 40
          }
        },
        "72cbc5dd1bee4b15964e2d672d0fd3ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e07bf838c4244e808e7b6d09254c9ef6",
            "placeholder": "",
            "style": "IPY_MODEL_baf745498197497c915d8bedf46891a8",
            "value": "40/10874[01:37&lt;7:21:14,0.41it/s,v_num=182,train_loss=0.917,train_acc=0.826,train_f1=0.000,train_auc=0.365]"
          }
        },
        "fd294fe7416b489ebf8d6ad271a5bf6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "61ec07a4eb03466bbb4a4bcb9a52a068": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f5b904caec44e9d8a9935490f1c973b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af2524c0cf91456fb00d584aca7a5a7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95215cd203944893bc42a6e978036c1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e07bf838c4244e808e7b6d09254c9ef6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baf745498197497c915d8bedf46891a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}