{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zfeng0207/FIT3199-FYP/blob/dev%2Fzfeng/multi-label-baseline-model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0CUDImu9MEW",
        "outputId": "10daddc1-d4e9-45ab-89ee-8d88b02a0369"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "h0CUDImu9MEW"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "GfQLwvb-9N2C"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/ECG-MIMIC-main')"
      ],
      "id": "GfQLwvb-9N2C"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "K_PGqhC8-C_A"
      },
      "outputs": [],
      "source": [
        "!pip install -qqqq mlflow torchmetrics pytorch_lightning iterative-stratification"
      ],
      "id": "K_PGqhC8-C_A"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3.5: Multihot encode: Setting up target binary labels"
      ],
      "metadata": {
        "id": "CEFykubaW1Lt"
      },
      "id": "CEFykubaW1Lt"
    },
    {
      "cell_type": "code",
      "source": [
        "def multihot_encode(diagnoses, icd_codes):\n",
        "    num_classes = len(icd_codes)\n",
        "    res = np.zeros(num_classes, dtype=np.float32)\n",
        "    for diag in diagnoses:\n",
        "        for i, code in enumerate(icd_codes):  # Iterate through icd_codes with index\n",
        "            if diag.startswith(code):\n",
        "                res[i] = 1\n",
        "                break\n",
        "    return res"
      ],
      "metadata": {
        "id": "4cugp1DhWv2g"
      },
      "execution_count": 44,
      "outputs": [],
      "id": "4cugp1DhWv2g"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDIT HERE!! Dataset Labeling"
      ],
      "metadata": {
        "id": "7ukBVHAvTc8e"
      },
      "id": "7ukBVHAvTc8e"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "# dataframe with 300,000 rows\n",
        "# df_full = pd.read_csv(\"src/data/label_df.csv\")\n",
        "\n",
        "# dataframe with 800,000 rows\n",
        "# df_full = pd.read_csv(\"src/data/records_w_diag_icd10.csv\")\n",
        "\n",
        "\n",
        "df_full['label_train'] = df_full['all_diag_all'].apply(\n",
        "    lambda x: str(list(set([code[:3] for code in ast.literal_eval(x)])))\n",
        ")\n",
        "df_labels =  df_full[[\"filename\",\n",
        "            \"study_id\",\n",
        "            \"patient_id\",\n",
        "            \"ecg_time\",\n",
        "            \"label_train\",\n",
        "            \"all_diag_all\"]]\n",
        "\n",
        "target_icd_codes = (\n",
        "   \"K74\", \"E11\"\n",
        ")\n",
        "\n",
        "# this is not working correctly fix this!\n",
        "df_labels['res'] = df_labels['label_train'].apply(lambda diagnoses: multihot_encode(diagnoses, target_icd_codes))\n",
        "\n",
        "# df_labels['stroke_yn'] = df_labels['res'].apply(lambda x: 1 if 1 in x else 0)\n",
        "\n",
        "# df_rm_nan = df_labels[df_labels['all_diag_all'].apply(lambda x: len(x) > 0)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAZEylGAXUTH",
        "outputId": "2c3d386d-94f5-4dbb-a47b-3ccd7bafd9fe"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-ae7d668c74a8>:27: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_labels['res'] = df_labels['label_train'].apply(lambda diagnoses: multihot_encode(diagnoses, target_icd_codes))\n"
          ]
        }
      ],
      "id": "xAZEylGAXUTH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Number of sparse target class"
      ],
      "metadata": {
        "id": "NLniNpIM-xzq"
      },
      "id": "NLniNpIM-xzq"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FSL0EeBhSzR2"
      },
      "id": "FSL0EeBhSzR2"
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_labels.copy()"
      ],
      "metadata": {
        "id": "UsGWZ61AUDPx"
      },
      "id": "UsGWZ61AUDPx",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def calculate_mean_positive_rate(df, label_col=\"res\"):\n",
        "    \"\"\"\n",
        "    Calculates the mean positive rate per label for a pandas DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The DataFrame containing the multi-hot labels.\n",
        "        label_col (str): The column name containing the multi-hot labels.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: An array containing the mean positive rate for each label.\n",
        "    \"\"\"\n",
        "\n",
        "    # Extract labels and ensure they are NumPy arrays with consistent shape\n",
        "    labels = df[label_col].apply(lambda x: np.array(x, dtype=np.float32)).values\n",
        "    labels = np.vstack(labels)  # Stack the labels into a 2D array\n",
        "\n",
        "\n",
        "    # Calculate mean positive rate per label\n",
        "    mean_positive_rate = labels.mean(axis=0)\n",
        "\n",
        "    return mean_positive_rate\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "mean_positive_rates = calculate_mean_positive_rate(df)\n",
        "\n",
        "# Print the results\n",
        "print(\"Mean positive rate per label:\", mean_positive_rates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmZetKparbjj",
        "outputId": "9bee22a6-1d23-46e7-b82a-9ba2a34d4a2f"
      },
      "id": "PmZetKparbjj",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean positive rate per label: [0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_empty_labels(df, label_col=\"res\"):\n",
        "    \"\"\"\n",
        "    Counts how many samples in the DataFrame have all-zero labels.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame containing the dataset\n",
        "        label_col (str): Column name containing the multi-hot labels\n",
        "\n",
        "    Returns:\n",
        "        int: Number of rows with all-zero labels\n",
        "    \"\"\"\n",
        "    empty_count = 0\n",
        "\n",
        "    for label_str in df[label_col]:\n",
        "        if label_str.sum() == 0:\n",
        "            empty_count += 1\n",
        "\n",
        "    return empty_count\n"
      ],
      "metadata": {
        "id": "jXbW93xRpdQ0"
      },
      "id": "jXbW93xRpdQ0",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "num_empty = count_empty_labels(df, label_col=\"res\")\n",
        "print(f\"There are {num_empty} samples with all-zero labels.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jBtnc_hpeaH",
        "outputId": "e147cf03-b557-4bca-d9a8-854651841ca1"
      },
      "id": "6jBtnc_hpeaH",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 800035 samples with all-zero labels.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configurations"
      ],
      "metadata": {
        "id": "afP60juTq6cc"
      },
      "id": "afP60juTq6cc"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "eaccf6f7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-10T16:44:05.670902Z",
          "start_time": "2023-07-10T16:44:05.654877Z"
        },
        "id": "eaccf6f7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "import os\n",
        "import platform\n",
        "\n",
        "# You can define ROOT_PATH somewhere above\n",
        "ROOT_PATH = \"/content/drive/MyDrive/Colab Notebooks (1)/ECG-MIMIC-main/src\"\n",
        "\n",
        "@dataclass\n",
        "class DatasetConfig:\n",
        "    # ECG-specific\n",
        "    NUM_LEADS:    int = 12  # 12 ECG channels (leads)\n",
        "    NUM_CLASSES:  int = 2  # 12 ICD disease codes\n",
        "    VALID_PCT:  float = 0.1\n",
        "\n",
        "    # Dataset file and folder paths\n",
        "    TRAIN_CSV:   str = os.path.join(ROOT_PATH, \"data/train.csv\")  # Your preprocessed split CSV\n",
        "    TEST_CSV:    str = os.path.join(ROOT_PATH, \"data/test.csv\")\n",
        "    MEMMAP_FILE: str = os.path.join(ROOT_PATH, \"ecg_dataset\", \"data/memmap/memmap.npy\")\n",
        "    MEMMAP_META: str = os.path.join(ROOT_PATH, \"ecg_dataset\", \"data/memmap/memmap_meta.npz\")\n",
        "\n",
        "@dataclass\n",
        "class TrainingConfig:\n",
        "    BATCH_SIZE:      int = 64\n",
        "    NUM_EPOCHS:      int = 30  # Actual training epochs\n",
        "    INIT_LR:       float = 1e-3\n",
        "    NUM_WORKERS:     int = 7\n",
        "    OPTIMIZER_NAME:  str = \"Adam\"\n",
        "    WEIGHT_DECAY:  float = 1e-4\n",
        "    USE_SCHEDULER:  bool = True\n",
        "    SCHEDULER:       str = \"multi_step_lr\"  # or \"cosine_annealing\"\n",
        "    F1_METRIC_THRESH: float = 0.5\n",
        "    FREEZE_BACKBONE: bool = False\n",
        "\n",
        "    # (Optional) model name (if you want to log it somewhere)\n",
        "    MODEL_NAME:      str = \"resnet18\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "42c43a81",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-10T16:44:07.044656Z",
          "start_time": "2023-07-10T16:44:07.029033Z"
        },
        "id": "42c43a81",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def encode_label(label: list, num_classes=10):\n",
        "    \"\"\"\n",
        "    This functions converts labels into multi-hot encoding.\n",
        "    Handles both single ICD codes and lists of codes.\n",
        "    \"\"\"\n",
        "    target = torch.zeros(num_classes)\n",
        "\n",
        "    # If label is a single code, make it a list\n",
        "    if isinstance(label, str):\n",
        "        label = [label]\n",
        "\n",
        "    for l in label:\n",
        "        # Check if 'l' contains brackets (indicating list within a string)\n",
        "        if '[' in l or ']' in l:\n",
        "            l = l.strip('[]').replace(\"'\", \"\").split(\",\")  # Handle list-like strings\n",
        "            for code in l:\n",
        "                code = code.strip()  # Remove any whitespace around code\n",
        "                if code in icd_to_index:\n",
        "                    target[icd_to_index[code]] = 1.0\n",
        "        else:\n",
        "            l = l.strip()  # Remove any whitespace around code\n",
        "            if l in icd_to_index:\n",
        "                target[icd_to_index[l]] = 1.0\n",
        "    return target\n",
        "\n",
        "\n",
        "def decode_target(\n",
        "    target: list,\n",
        "    text_labels: bool = False,\n",
        "    threshold: float = 0.4,\n",
        "    cls_labels: dict = None,\n",
        "):\n",
        "    \"\"\"This function converts the labels from\n",
        "    probablities to outputs or string representations\n",
        "    \"\"\"\n",
        "\n",
        "    result = []\n",
        "    for i, x in enumerate(target):\n",
        "        if x >= threshold:\n",
        "            if text_labels:\n",
        "                result.append(cls_labels[i] + \"(\" + str(i) + \")\")\n",
        "            else:\n",
        "                result.append(str(i))\n",
        "    return \" \".join(result)\n",
        "\n",
        "\n",
        "# This function is used for reversing the Normalization step performed\n",
        "# during image preprocessing.\n",
        "# Note the mean and std values must match the ones used.\n",
        "\n",
        "def denormalize(tensors, *, mean, std):\n",
        "    \"\"\"Denormalizes image tensors using mean and std provided\n",
        "    and clip values between 0 and 1\"\"\"\n",
        "\n",
        "    for c in range(DatasetConfig.CHANNELS):\n",
        "        tensors[:, c, :, :].mul_(std[c]).add_(mean[c])\n",
        "\n",
        "    return torch.clamp(tensors, min=0.0, max=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary mapping ICD codes to index\n",
        "# icd_to_index = {code: idx for idx, code in enumerate(target_icd_codes)}\n"
      ],
      "metadata": {
        "id": "OmWT4BbUvxAM"
      },
      "id": "OmWT4BbUvxAM",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "aEHP8HuiG06q"
      },
      "id": "aEHP8HuiG06q"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class ECGDataset(Dataset):\n",
        "    def __init__(self, dataframe, memmap, memmap_meta, normalize=True, indices=None):  # Add indices argument\n",
        "        self.df = dataframe.reset_index(drop=True)\n",
        "        self.memmap = memmap\n",
        "        self.memmap_meta = memmap_meta  # Store memmap_meta\n",
        "        self.normalize = normalize\n",
        "        self.num_classes = DatasetConfig.NUM_CLASSES\n",
        "        self.indices = indices  # Store indices if provided\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            memmap_path (str): Path to the .npy memory-mapped ECG file.\n",
        "            meta_path (str): Path to the .npz metadata file.\n",
        "        \"\"\"\n",
        "        self.starts = self.memmap_meta[\"start\"]\n",
        "        self.lengths = self.memmap_meta[\"length\"]\n",
        "        self.shape = tuple(self.memmap_meta[\"shape\"][0])\n",
        "        self.ecg_data = self.memmap.reshape(self.shape)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices) if self.indices is not None else len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the actual index from the indices list if provided\n",
        "        actual_idx = self.indices[idx] if self.indices is not None else idx\n",
        "\n",
        "        # Access starts and lengths using actual_idx\n",
        "        start_idx = self.starts[actual_idx]\n",
        "        length = self.lengths[actual_idx]\n",
        "\n",
        "        signal = self.ecg_data[start_idx:start_idx + length, :]\n",
        "        # signal = (signal - signal.mean(axis=0)) / (signal.std(axis=0) + 1e-6)\n",
        "\n",
        "        # Reshape to [length, 12]\n",
        "        signal = signal.T\n",
        "\n",
        "        # Convert signal to PyTorch tensor before checking for NaN/inf\n",
        "        signal = torch.tensor(signal, dtype=torch.float32)\n",
        "        label = self.df.loc[actual_idx]['res']  # shape: (length, 12)\n",
        "\n",
        "        return signal, label\n"
      ],
      "metadata": {
        "id": "lsAaJZGFleNl"
      },
      "id": "lsAaJZGFleNl",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Module"
      ],
      "metadata": {
        "id": "oll9G-J7G3GB"
      },
      "id": "oll9G-J7G3GB"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "0d6a7838",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-10T16:44:07.092291Z",
          "start_time": "2023-07-10T16:44:07.060054Z"
        },
        "id": "0d6a7838",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold, MultilabelStratifiedShuffleSplit\n",
        "\n",
        "class ECGDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, dataframe, memmap_meta, memmap, batch_size, num_workers, pin_memory, valid_pct, normalize=True, shuffle_validation=False): # Add shuffle_validation as a parameter\n",
        "        super().__init__()\n",
        "        self.dataframe = dataframe  # Full df\n",
        "        self.memmap_meta = memmap_meta\n",
        "        self.memmap = memmap\n",
        "        self.normalize = normalize\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        self.pin_memory = pin_memory\n",
        "        self.valid_pct = valid_pct\n",
        "        self.shuffle_validation = shuffle_validation\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        label_cols = 'res'\n",
        "        np.random.seed(42)\n",
        "\n",
        "        # Prepare your multi-hot label matrix\n",
        "        self.dataframe[label_cols] = self.dataframe[label_cols].apply(lambda x: np.fromstring(x[1:-1], dtype=float, sep=' ') if isinstance(x, str) else x)\n",
        "        Y = np.vstack(self.dataframe[label_cols].values)\n",
        "\n",
        "        # 1. Split indices instead of the DataFrame\n",
        "        splitter = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "        train_val_idx, test_idx = next(splitter.split(self.dataframe, Y))\n",
        "\n",
        "        splitter_val = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\n",
        "        Y_train_val = np.vstack(self.dataframe.iloc[train_val_idx][label_cols].apply(lambda x: np.array(x, dtype=np.float32)).values)\n",
        "        train_idx, val_idx = next(splitter_val.split(self.dataframe.iloc[train_val_idx], Y_train_val))\n",
        "\n",
        "        # 2. Store the indices as attributes\n",
        "        self.train_idx = train_idx\n",
        "        self.val_idx = val_idx\n",
        "        self.test_idx = test_idx\n",
        "\n",
        "        # 3. Create datasets, passing the whole dataframe\n",
        "        self.train_ds = ECGDataset(\n",
        "            dataframe=self.dataframe,  # Passing the whole DataFrame\n",
        "            memmap=self.memmap,\n",
        "            memmap_meta=self.memmap_meta,\n",
        "            normalize=self.normalize,\n",
        "            indices=self.train_idx,  # Passing train indices\n",
        "        )\n",
        "\n",
        "        self.valid_ds = ECGDataset(\n",
        "            dataframe=self.dataframe,  # Passing the whole DataFrame\n",
        "            memmap=self.memmap,\n",
        "            memmap_meta=self.memmap_meta,\n",
        "            normalize=self.normalize,\n",
        "            indices=self.val_idx,  # Passing train indices\n",
        "        )\n",
        "\n",
        "        self.test_ds = ECGDataset(\n",
        "            dataframe=self.dataframe,  # Passing the whole DataFrame\n",
        "            memmap=self.memmap,\n",
        "            memmap_meta=self.memmap_meta,\n",
        "            normalize=self.normalize,\n",
        "            indices=self.test_idx,  # Passing train indices\n",
        "        )\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_ds,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=self.num_workers,\n",
        "            pin_memory=self.pin_memory,\n",
        "            # collate_fn=pad_collate, # Apply padding collate function\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.valid_ds,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=self.shuffle_validation, # Use the instance variable\n",
        "            num_workers=self.num_workers,\n",
        "            pin_memory=self.pin_memory,\n",
        "            # collate_fn=pad_collate, # Apply padding collate function\n",
        "\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        # Optional: If you set up a test set later\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "91ee71b8",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2023-07-10T16:43:46.064Z"
        },
        "id": "91ee71b8"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "\n",
        "def get_model(model_name: str, num_classes: int, freeze_backbone: bool= True):\n",
        "    \"\"\"A helper function to load and prepare any classification model\n",
        "    available in Torchvision for transfer learning or fine-tuning.\"\"\"\n",
        "\n",
        "    model = getattr(torchvision.models, model_name)(weights=\"DEFAULT\")\n",
        "\n",
        "    if freeze_backbone:\n",
        "        # Set all layer to be non-trainable\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    model_childrens = [name for name, _ in model.named_children()]\n",
        "\n",
        "    try:\n",
        "        final_layer_in_features = getattr(model, f\"{model_childrens[-1]}\")[-1].in_features\n",
        "    except Exception as e:\n",
        "        final_layer_in_features = getattr(model, f\"{model_childrens[-1]}\").in_features\n",
        "\n",
        "    new_output_layer = nn.Linear(\n",
        "        in_features=final_layer_in_features,\n",
        "        out_features=num_classes\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        getattr(model, f\"{model_childrens[-1]}\")[-1] = new_output_layer\n",
        "    except:\n",
        "        setattr(model, model_childrens[-1], new_output_layer)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f953896",
      "metadata": {
        "id": "3f953896"
      },
      "source": [
        "**Function usage example:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcT1fLY8wZVc",
        "outputId": "73f54c0c-dd02-4002-9fc6-361a43e67dba"
      },
      "id": "qcT1fLY8wZVc",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (1.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "3696a2b6",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2023-07-10T16:43:46.070Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3696a2b6",
        "outputId": "803af1ba-ae80-4078-dda3-42e1b59b169a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===================================================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #                   Trainable\n",
              "===================================================================================================================\n",
              "ResNet                                   [64, 2]                   --                        True\n",
              "├─Conv2d: 1-1                            [64, 64, 500, 1]          5,376                     True\n",
              "├─BatchNorm2d: 1-2                       [64, 64, 500, 1]          128                       True\n",
              "├─ReLU: 1-3                              [64, 64, 500, 1]          --                        --\n",
              "├─MaxPool2d: 1-4                         [64, 64, 250, 1]          --                        --\n",
              "├─Sequential: 1-5                        [64, 64, 250, 1]          --                        True\n",
              "│    └─BasicBlock: 2-1                   [64, 64, 250, 1]          73,984                    True\n",
              "│    └─BasicBlock: 2-2                   [64, 64, 250, 1]          73,984                    True\n",
              "├─Sequential: 1-6                        [64, 128, 125, 1]         --                        True\n",
              "│    └─BasicBlock: 2-3                   [64, 128, 125, 1]         230,144                   True\n",
              "│    └─BasicBlock: 2-4                   [64, 128, 125, 1]         295,424                   True\n",
              "├─Sequential: 1-7                        [64, 256, 63, 1]          --                        True\n",
              "│    └─BasicBlock: 2-5                   [64, 256, 63, 1]          919,040                   True\n",
              "│    └─BasicBlock: 2-6                   [64, 256, 63, 1]          1,180,672                 True\n",
              "├─Sequential: 1-8                        [64, 512, 32, 1]          --                        True\n",
              "│    └─BasicBlock: 2-7                   [64, 512, 32, 1]          3,673,088                 True\n",
              "│    └─BasicBlock: 2-8                   [64, 512, 32, 1]          4,720,640                 True\n",
              "├─AdaptiveAvgPool2d: 1-9                 [64, 512, 1, 1]           --                        --\n",
              "├─Linear: 1-10                           [64, 2]                   1,026                     True\n",
              "===================================================================================================================\n",
              "Total params: 11,173,506\n",
              "Trainable params: 11,173,506\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.GIGABYTES): 32.36\n",
              "===================================================================================================================\n",
              "Input size (MB): 3.07\n",
              "Forward/backward pass size (MB): 346.69\n",
              "Params size (MB): 44.69\n",
              "Estimated Total Size (MB): 394.45\n",
              "==================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "# from torchinfo import summary\n",
        "# import torch.nn as nn\n",
        "\n",
        "# # Suppose your ECG signals are 1000 time steps long\n",
        "# TIME_LENGTH = 1000\n",
        "\n",
        "# model = get_model(\n",
        "#     model_name=TrainingConfig.MODEL_NAME,    # Should be \"resnet50\"\n",
        "#     num_classes=DatasetConfig.NUM_CLASSES,\n",
        "#     freeze_backbone=False,\n",
        "# )\n",
        "\n",
        "# # Correctly modify the first convolutional layer to accept 12 channels\n",
        "# model.conv1 = nn.Conv2d(in_channels=12, out_channels=64, kernel_size=(7, 1), stride=(2, 1), padding=(3, 0), bias=False) # Reassign the layer\n",
        "\n",
        "# # Proper ECG input shape\n",
        "# summary(\n",
        "#     model,\n",
        "#     input_size=(TrainingConfig.BATCH_SIZE, DatasetConfig.NUM_LEADS, TIME_LENGTH, 1),  # (batch, channels=12, time, width=1)\n",
        "#     depth=2,\n",
        "#     device=\"cpu\",\n",
        "#     col_names=[\"output_size\", \"num_params\", \"trainable\"]\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Assuming 'df' is your DataFrame and 'res' is the column with labels\n",
        "# class_frequencies = []\n",
        "# for code in target_icd_codes:\n",
        "#     # Count occurrences of the current code in the 'res' column\n",
        "#     freq = df['res'].str.contains(code).sum()\n",
        "#     class_frequencies.append(freq)\n",
        "\n",
        "# # Convert the list to a PyTorch tensor\n",
        "# class_frequencies = torch.tensor(class_frequencies, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "yJudCyPyPuV5"
      },
      "id": "yJudCyPyPuV5",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "BOn3XvNs8bqV"
      },
      "id": "BOn3XvNs8bqV"
    },
    {
      "source": [
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "\n",
        "class Swish(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(x)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "p7AO6C9-8TkZ"
      },
      "execution_count": 60,
      "outputs": [],
      "id": "p7AO6C9-8TkZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ConvNormPool"
      ],
      "metadata": {
        "id": "e8spFZLq7ccJ"
      },
      "id": "e8spFZLq7ccJ"
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNormPool(pl.LightningModule):\n",
        "    \"\"\"Conv Skip-connection module\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size,\n",
        "        hidden_size,\n",
        "        kernel_size,\n",
        "        norm_type='bachnorm'\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.kernel_size = kernel_size\n",
        "        self.conv_1 = nn.Conv1d(\n",
        "            in_channels=input_size,\n",
        "            out_channels=hidden_size,\n",
        "            kernel_size=kernel_size\n",
        "        )\n",
        "        self.conv_2 = nn.Conv1d(\n",
        "            in_channels=hidden_size,\n",
        "            out_channels=hidden_size,\n",
        "            kernel_size=kernel_size\n",
        "        )\n",
        "        self.conv_3 = nn.Conv1d(\n",
        "            in_channels=hidden_size,\n",
        "            out_channels=hidden_size,\n",
        "            kernel_size=kernel_size\n",
        "        )\n",
        "        self.swish_1 = Swish()\n",
        "        self.swish_2 = Swish()\n",
        "        self.swish_3 = Swish()\n",
        "        if norm_type == 'group':\n",
        "            self.normalization_1 = nn.GroupNorm(\n",
        "                num_groups=8,\n",
        "                num_channels=hidden_size\n",
        "            )\n",
        "            self.normalization_2 = nn.GroupNorm(\n",
        "                num_groups=8,\n",
        "                num_channels=hidden_size\n",
        "            )\n",
        "            self.normalization_3 = nn.GroupNorm(\n",
        "                num_groups=8,\n",
        "                num_channels=hidden_size\n",
        "            )\n",
        "        else:\n",
        "            self.normalization_1 = nn.BatchNorm1d(num_features=hidden_size)\n",
        "            self.normalization_2 = nn.BatchNorm1d(num_features=hidden_size)\n",
        "            self.normalization_3 = nn.BatchNorm1d(num_features=hidden_size)\n",
        "\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
        "\n",
        "    def forward(self, input):\n",
        "        conv1 = self.conv_1(input)\n",
        "        x = self.normalization_1(conv1)\n",
        "        x = self.swish_1(x)\n",
        "        x = F.pad(x, pad=(self.kernel_size - 1, 0))\n",
        "\n",
        "        x = self.conv_2(x)\n",
        "        x = self.normalization_2(x)\n",
        "        x = self.swish_2(x)\n",
        "        x = F.pad(x, pad=(self.kernel_size - 1, 0))\n",
        "\n",
        "        conv3 = self.conv_3(x)\n",
        "        x = self.normalization_3(conv1+conv3)\n",
        "        x = self.swish_3(x)\n",
        "        x = F.pad(x, pad=(self.kernel_size - 1, 0))\n",
        "\n",
        "        x = self.pool(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "NPtpv9_j6Ywv"
      },
      "execution_count": 61,
      "outputs": [],
      "id": "NPtpv9_j6Ywv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN"
      ],
      "metadata": {
        "id": "M7itc5Nq7fCM"
      },
      "id": "M7itc5Nq7fCM"
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(pl.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size = 1,\n",
        "        hid_size = 256,\n",
        "        kernel_size = 5,\n",
        "        num_classes = 5,\n",
        "    ):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = ConvNormPool(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hid_size,\n",
        "            kernel_size=kernel_size,\n",
        "        )\n",
        "        self.conv2 = ConvNormPool(\n",
        "            input_size=hid_size,\n",
        "            hidden_size=hid_size//2,\n",
        "            kernel_size=kernel_size,\n",
        "        )\n",
        "        self.conv3 = ConvNormPool(\n",
        "            input_size=hid_size//2,\n",
        "            hidden_size=hid_size//4,\n",
        "            kernel_size=kernel_size,\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool1d((1))\n",
        "        self.fc = nn.Linear(in_features=hid_size//4, out_features=num_classes)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.conv1(input)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.avgpool(x)\n",
        "        # print(x.shape) # num_features * num_channels\n",
        "        x = x.view(-1, x.size(1) * x.size(2))\n",
        "        x = F.softmax(self.fc(x), dim=1)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "_HLYf3RW6hNe"
      },
      "execution_count": 62,
      "outputs": [],
      "id": "_HLYf3RW6hNe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN"
      ],
      "metadata": {
        "id": "BjoJ234gFYOa"
      },
      "id": "BjoJ234gFYOa"
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(pl.LightningModule):\n",
        "    \"\"\"RNN module(cell type lstm or gru)\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size,\n",
        "        hid_size,\n",
        "        num_rnn_layers=1,\n",
        "        dropout_p = 0.2,\n",
        "        bidirectional = False,\n",
        "        rnn_type = 'lstm',\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        if rnn_type == 'lstm':\n",
        "            self.rnn_layer = nn.LSTM(\n",
        "                input_size=input_size,\n",
        "                hidden_size=hid_size,\n",
        "                num_layers=num_rnn_layers,\n",
        "                dropout=dropout_p if num_rnn_layers>1 else 0,\n",
        "                bidirectional=bidirectional,\n",
        "                batch_first=True,\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            self.rnn_layer = nn.GRU(\n",
        "                input_size=input_size,\n",
        "                hidden_size=hid_size,\n",
        "                num_layers=num_rnn_layers,\n",
        "                dropout=dropout_p if num_rnn_layers>1 else 0,\n",
        "                bidirectional=bidirectional,\n",
        "                batch_first=True,\n",
        "            )\n",
        "    def forward(self, input):\n",
        "        outputs, hidden_states = self.rnn_layer(input)\n",
        "        return outputs, hidden_states\n"
      ],
      "metadata": {
        "id": "OHzkyOyw74yI"
      },
      "execution_count": 63,
      "outputs": [],
      "id": "OHzkyOyw74yI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN Model"
      ],
      "metadata": {
        "id": "f2fFMO5j7ijR"
      },
      "id": "f2fFMO5j7ijR"
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNModel(pl.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size,\n",
        "        hid_size,\n",
        "        rnn_type,\n",
        "        bidirectional,\n",
        "        n_classes=5,\n",
        "        kernel_size=5,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.rnn_layer = RNN(\n",
        "            input_size=46,#hid_size * 2 if bidirectional else hid_size,\n",
        "            hid_size=hid_size,\n",
        "            rnn_type=rnn_type,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "        self.conv1 = ConvNormPool(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hid_size,\n",
        "            kernel_size=kernel_size,\n",
        "        )\n",
        "        self.conv2 = ConvNormPool(\n",
        "            input_size=hid_size,\n",
        "            hidden_size=hid_size,\n",
        "            kernel_size=kernel_size,\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool1d((1))\n",
        "        self.fc = nn.Linear(in_features=hid_size, out_features=n_classes)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.conv1(input)\n",
        "        x = self.conv2(x)\n",
        "        x, _ = self.rnn_layer(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(-1, x.size(1) * x.size(2))\n",
        "        x = F.sigmoid(self.fc(x), dim=1)#.squeeze(1)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "bbaUcwi-6j6A"
      },
      "execution_count": 64,
      "outputs": [],
      "id": "bbaUcwi-6j6A"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN Attention Model"
      ],
      "metadata": {
        "id": "dXKYZVjn9Zrk"
      },
      "id": "dXKYZVjn9Zrk"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pytorch_lightning as pl\n",
        "from torchmetrics.classification import MultilabelAccuracy, MultilabelF1Score, MultilabelAUROC\n",
        "\n",
        "class RNNAttentionModel(pl.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        hid_size =64,\n",
        "        rnn_type = 'lstm',\n",
        "        bidirectional=False,\n",
        "        num_classes=2,\n",
        "        input_size =12,\n",
        "        kernel_size=5,\n",
        "        lr=1e-3,\n",
        "        f1_metric_threshold=0.5,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.conv1 = ConvNormPool(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hid_size,\n",
        "            kernel_size=kernel_size,\n",
        "        )\n",
        "        self.conv2 = ConvNormPool(\n",
        "            input_size=hid_size,\n",
        "            hidden_size=hid_size,\n",
        "            kernel_size=kernel_size,\n",
        "        )\n",
        "\n",
        "        self.rnn_layer = RNN(\n",
        "            input_size=hid_size,\n",
        "            hid_size=hid_size,\n",
        "            rnn_type=rnn_type,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "\n",
        "        self.attn = nn.Linear(hid_size, hid_size, bias=False)\n",
        "        self.fc = nn.Linear(in_features=hid_size, out_features=num_classes)  # Multi-label output\n",
        "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
        "        self.lr = lr\n",
        "\n",
        "        # Metrics\n",
        "        self.train_acc = MultilabelAccuracy(num_labels=num_classes, threshold=f1_metric_threshold)\n",
        "        self.train_f1 = MultilabelF1Score(num_labels=num_classes, average=\"macro\", threshold=f1_metric_threshold)\n",
        "        self.train_auc = MultilabelAUROC(num_labels=num_classes)\n",
        "\n",
        "        self.val_acc = MultilabelAccuracy(num_labels=num_classes, threshold=f1_metric_threshold)\n",
        "        self.val_f1 = MultilabelF1Score(num_labels=num_classes, average=\"macro\", threshold=f1_metric_threshold)\n",
        "        self.val_auc = MultilabelAUROC(num_labels=num_classes)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # input = input.permute(0, 2, 1)  # Remove this line - permutation is done in the dataset\n",
        "        x = self.conv1(input)\n",
        "        x = self.conv2(x)\n",
        "        x = x.permute(0, 2, 1)  # Permute before the RNN layer\n",
        "\n",
        "        x_out, _ = self.rnn_layer(x)\n",
        "\n",
        "        attn_weights = torch.softmax(self.attn(x_out), dim=1)\n",
        "        x = torch.sum(attn_weights * x_out, dim=1)\n",
        "\n",
        "        logits = self.fc(x)\n",
        "        return logits\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.loss_fn(logits, y.float())\n",
        "        probs = torch.sigmoid(logits)\n",
        "\n",
        "        acc = self.train_acc(probs, y.int())\n",
        "        f1 = self.train_f1(probs, y.int())\n",
        "        auc = self.train_auc(probs, y.int())\n",
        "\n",
        "        self.log(\"train_loss\", loss, prog_bar=True)\n",
        "        self.log(\"train_acc\", acc, prog_bar=True)\n",
        "        self.log(\"train_f1\", f1, prog_bar=True)\n",
        "        self.log(\"train_auc\", auc, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.loss_fn(logits, y.float())\n",
        "        probs = torch.sigmoid(logits)\n",
        "\n",
        "        acc = self.val_acc(probs, y.int())\n",
        "        f1 = self.val_f1(probs, y.int())\n",
        "        auc = self.val_auc(probs, y.int())\n",
        "\n",
        "        self.log(\"val_loss\", loss, prog_bar=True)\n",
        "        self.log(\"val_acc\", acc, prog_bar=True)\n",
        "        self.log(\"val_f1\", f1, prog_bar=True)\n",
        "        self.log(\"val_auc\", auc, prog_bar=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=self.lr)"
      ],
      "metadata": {
        "id": "-1pz8ZdK9d-1"
      },
      "execution_count": 65,
      "outputs": [],
      "id": "-1pz8ZdK9d-1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Initialization"
      ],
      "metadata": {
        "id": "gdZWRSKrG_EA"
      },
      "id": "gdZWRSKrG_EA"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "ee9cff32-b77e-4fc6-8cde-c9d67b431263",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2023-07-10T16:43:46.083Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee9cff32-b77e-4fc6-8cde-c9d67b431263",
        "outputId": "0d870004-9ae0-45a4-a28d-c24fd3f6a2e0",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n"
          ]
        }
      ],
      "source": [
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
        "\n",
        "# 1. Seed everything for reproducibility\n",
        "pl.seed_everything(42, workers=True)\n",
        "\n",
        "memmap_path = \"src/data/memmap/memmap.npy\"\n",
        "\n",
        "memmap_data = np.memmap(memmap_path, dtype=np.float32, mode='r')\n",
        "memmap_meta_path = \"src/data/memmap/memmap_meta.npz\"\n",
        "memmap_meta = np.load(memmap_meta_path, allow_pickle=True)\n",
        "# Instantiate the ECGDataModule\n",
        "dm = ECGDataModule(\n",
        "    dataframe=df,            # Your loaded DataFrame\n",
        "    memmap=memmap_data,             # Your loaded memmap\n",
        "    memmap_meta = memmap_meta,\n",
        "    batch_size=TrainingConfig.BATCH_SIZE,\n",
        "    num_workers=TrainingConfig.NUM_WORKERS,\n",
        "    pin_memory=torch.cuda.is_available(),\n",
        "    valid_pct=DatasetConfig.VALID_PCT,\n",
        ")\n",
        "\n",
        "# Prepare data (nothing to download for ECG, so will pass)\n",
        "dm.prepare_data()\n",
        "\n",
        "# Split dataset into training and validation sets\n",
        "dm.setup()\n",
        "\n",
        "# 4. Create ModelCheckpoint callback\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    monitor=\"valid/f1\",        # Monitor validation F1 score\n",
        "    mode=\"max\",                # Maximize F1\n",
        "    filename=\"ecg_epoch{epoch:03d}_vloss{valid/loss:.4f}_vf1{valid/f1:.4f}\",\n",
        "    auto_insert_metric_name=False,\n",
        "    save_top_k=1,              # Save the best model only\n",
        ")\n",
        "\n",
        "# 5. Create Learning Rate Monitor callback\n",
        "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "fed847ae-7330-43f3-90fa-85bbd10f498f",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2023-07-10T16:43:46.088Z"
        },
        "id": "fed847ae-7330-43f3-90fa-85bbd10f498f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# # To reload tensorBoard\n",
        "# %reload_ext tensorboard\n",
        "\n",
        "# # logs folder path\n",
        "# %tensorboard --logdir=lightning_logs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83c7a942",
      "metadata": {
        "id": "83c7a942"
      },
      "source": [
        "**Train**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "B_KsibxBZorA"
      },
      "id": "B_KsibxBZorA"
    },
    {
      "cell_type": "code",
      "source": [
        "# # Access train_dataloader through the dm instance\n",
        "# for batch in dm.train_dataloader():  # Call train_dataloader() on dm\n",
        "#     signals, labels = batch\n",
        "#     print(\"Sample labels:\", labels[:5])\n",
        "#     print(\"Mean positive rate per label:\", labels.mean(dim=0))\n",
        "#     break"
      ],
      "metadata": {
        "id": "0zv1qYEQpOUo"
      },
      "id": "0zv1qYEQpOUo",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Assuming 'dm' is your ECGDataModule instance\n",
        "# train_loader = dm.train_dataloader()\n",
        "\n",
        "# # 1. Using len() on the dataloader:\n",
        "# num_batches = len(train_loader)\n",
        "# print(f\"Number of batches in train_dataloader: {num_batches}\")\n",
        "\n",
        "# # 2. Calculating total samples from batch size and num_batches:\n",
        "# total_samples = num_batches * train_loader.batch_size\n",
        "# print(f\"Estimated total samples in training dataset: {total_samples}\")\n",
        "\n",
        "# # 3. Accessing the underlying dataset directly (more accurate):\n",
        "# total_samples_accurate = len(train_loader.dataset)\n",
        "# print(f\"Actual total samples in training dataset: {total_samples_accurate}\")\n"
      ],
      "metadata": {
        "id": "CRUY44K5yODQ"
      },
      "id": "CRUY44K5yODQ",
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNNAttentionModel()"
      ],
      "metadata": {
        "id": "5v4bo0sE4jXl"
      },
      "id": "5v4bo0sE4jXl",
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(\n",
        "    model,\n",
        "    input_size=(TrainingConfig.BATCH_SIZE, DatasetConfig.NUM_LEADS, TIME_LENGTH),  # (batch, channels=12, time, width=1)\n",
        "    depth=2,\n",
        "    device=\"cpu\",\n",
        "    col_names=[\"output_size\", \"num_params\", \"trainable\"]\n",
        ")"
      ],
      "metadata": {
        "id": "Km4aQkHHyW-g",
        "outputId": "23cab4eb-812b-4b93-a6ca-a0b54dbc6795",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Km4aQkHHyW-g",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===================================================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #                   Trainable\n",
              "===================================================================================================================\n",
              "RNNAttentionModel                        [64, 2]                   --                        True\n",
              "├─ConvNormPool: 1-1                      [64, 64, 500]             --                        True\n",
              "│    └─Conv1d: 2-1                       [64, 64, 996]             3,904                     True\n",
              "│    └─BatchNorm1d: 2-2                  [64, 64, 996]             128                       True\n",
              "│    └─Swish: 2-3                        [64, 64, 996]             --                        --\n",
              "│    └─Conv1d: 2-4                       [64, 64, 996]             20,544                    True\n",
              "│    └─BatchNorm1d: 2-5                  [64, 64, 996]             128                       True\n",
              "│    └─Swish: 2-6                        [64, 64, 996]             --                        --\n",
              "│    └─Conv1d: 2-7                       [64, 64, 996]             20,544                    True\n",
              "│    └─BatchNorm1d: 2-8                  [64, 64, 996]             128                       True\n",
              "│    └─Swish: 2-9                        [64, 64, 996]             --                        --\n",
              "│    └─MaxPool1d: 2-10                   [64, 64, 500]             --                        --\n",
              "├─ConvNormPool: 1-2                      [64, 64, 250]             --                        True\n",
              "│    └─Conv1d: 2-11                      [64, 64, 496]             20,544                    True\n",
              "│    └─BatchNorm1d: 2-12                 [64, 64, 496]             128                       True\n",
              "│    └─Swish: 2-13                       [64, 64, 496]             --                        --\n",
              "│    └─Conv1d: 2-14                      [64, 64, 496]             20,544                    True\n",
              "│    └─BatchNorm1d: 2-15                 [64, 64, 496]             128                       True\n",
              "│    └─Swish: 2-16                       [64, 64, 496]             --                        --\n",
              "│    └─Conv1d: 2-17                      [64, 64, 496]             20,544                    True\n",
              "│    └─BatchNorm1d: 2-18                 [64, 64, 496]             128                       True\n",
              "│    └─Swish: 2-19                       [64, 64, 496]             --                        --\n",
              "│    └─MaxPool1d: 2-20                   [64, 64, 250]             --                        --\n",
              "├─RNN: 1-3                               [64, 250, 64]             --                        True\n",
              "│    └─LSTM: 2-21                        [64, 250, 64]             33,280                    True\n",
              "├─Linear: 1-4                            [64, 250, 64]             4,096                     True\n",
              "├─Linear: 1-5                            [64, 2]                   130                       True\n",
              "===================================================================================================================\n",
              "Total params: 144,898\n",
              "Trainable params: 144,898\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.GIGABYTES): 5.36\n",
              "===================================================================================================================\n",
              "Input size (MB): 3.07\n",
              "Forward/backward pass size (MB): 309.72\n",
              "Params size (MB): 0.58\n",
              "Estimated Total Size (MB): 313.38\n",
              "==================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "909e0f0d",
      "metadata": {
        "id": "909e0f0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685,
          "referenced_widgets": [
            "b2b5eedb4b5644a38aad4c3ac655532a",
            "62f70677b96345a093ceebca6be02816",
            "910f1dc327304ff1b790ed441a95b8da",
            "0e44389e9bc54425a683e04c5383a1dc",
            "46145b984ebe4a8d97e88847958bcdc0",
            "df2326d97a0f423dbbc1431c3f07c3be",
            "c9c40660a7334e1cba9b2f5fdfae1ae4",
            "4c87886325ef49b8b6a5ad867255248e",
            "f15a2f72b5ce43e1b16f1eac44642b0d",
            "2205df24a40e49189f4659ddb52a5407",
            "3c606d1b744245f082fe14be1d3583b0",
            "43d533e2aadd468ea4df2ea73b7a8c2b",
            "b2245f3b285d43a2afad643bce20ba35",
            "87c4fca857b344b684b654ed113597ec",
            "bad6471fee444b4f84476d0c13668104",
            "4f766201aa1f4223b11ff4a06747cced",
            "e75bcc8e3ebb4c6b89da141e07b4e0df",
            "87a03836c37143019662d8bb81d4640c",
            "e6e95484cb6c412a887a9ade477a7f22",
            "959a2db5b89649c1aa22a3723d5298c7",
            "329a9d895c57421fa1d28d7a29f52607",
            "6ff70e6d1dc74bd995c133f4d238fcd8"
          ]
        },
        "outputId": "5233226d-355c-49fd-de3e-79646dc1b993"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightning_fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:513: You passed `Trainer(accelerator='cpu', precision='16-mixed')` but AMP with fp16 is not supported on CPU. Using `precision='bf16-mixed'` instead.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2b5eedb4b5644a38aad4c3ac655532a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
            "  warnings.warn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43d533e2aadd468ea4df2ea73b7a8c2b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:\n",
            "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'exit' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    598\u001b[0m         )\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0mdataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m             \u001b[0;31m# TODO: we should instead use the batch_idx returned by the fetcher, however, that will require saving the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/fetchers.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# this will run only when no pre-fetching was done.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/fetchers.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/utilities/combined_loader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Sequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/utilities/combined_loader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1421\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    947\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-8725c5787278>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    562\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_SubprocessScriptLauncher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_sigkill_signal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
          ]
        }
      ],
      "source": [
        "# Initializing the Trainer class object.\n",
        "# It uses 'Tensorboard' as its default logger.\n",
        "trainer = pl.Trainer(\n",
        "    accelerator=\"auto\", # Auto select the best hardware accelerator available\n",
        "    devices=\"auto\", # Auto select available devices for the accelerator (For eg. mutiple GPUs)\n",
        "    strategy=\"auto\", # Auto select the distributed training strategy.\n",
        "    max_epochs=TrainingConfig.NUM_EPOCHS, # Maximum number of epoch to train for.\n",
        "    deterministic=True, # For deteministic and reproducible training.\n",
        "    enable_model_summary=False, # Disable printing of model summary as we are using torchinfo.\n",
        "    callbacks=[model_checkpoint, lr_monitor],  # Declaring callbacks to use.\n",
        "    precision=\"16\", # Using Mixed Precision training.\n",
        "    logger=True, # Auto generate TensorBoard logs.\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.fit(model, dm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7714dd0f-502c-4297-ad13-a24655ca7c5d",
      "metadata": {
        "id": "7714dd0f-502c-4297-ad13-a24655ca7c5d"
      },
      "source": [
        "## 7 Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa9333e2",
      "metadata": {
        "id": "fa9333e2"
      },
      "source": [
        "To perform inference, first, we need to load the best checkpoint saved during training. We can do it simply by executing the following:"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "379.387px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b2b5eedb4b5644a38aad4c3ac655532a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62f70677b96345a093ceebca6be02816",
              "IPY_MODEL_910f1dc327304ff1b790ed441a95b8da",
              "IPY_MODEL_0e44389e9bc54425a683e04c5383a1dc"
            ],
            "layout": "IPY_MODEL_46145b984ebe4a8d97e88847958bcdc0"
          }
        },
        "62f70677b96345a093ceebca6be02816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df2326d97a0f423dbbc1431c3f07c3be",
            "placeholder": "​",
            "style": "IPY_MODEL_c9c40660a7334e1cba9b2f5fdfae1ae4",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "910f1dc327304ff1b790ed441a95b8da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c87886325ef49b8b6a5ad867255248e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f15a2f72b5ce43e1b16f1eac44642b0d",
            "value": 2
          }
        },
        "0e44389e9bc54425a683e04c5383a1dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2205df24a40e49189f4659ddb52a5407",
            "placeholder": "​",
            "style": "IPY_MODEL_3c606d1b744245f082fe14be1d3583b0",
            "value": " 2/2 [00:03&lt;00:00,  0.60it/s]"
          }
        },
        "46145b984ebe4a8d97e88847958bcdc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "df2326d97a0f423dbbc1431c3f07c3be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9c40660a7334e1cba9b2f5fdfae1ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c87886325ef49b8b6a5ad867255248e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f15a2f72b5ce43e1b16f1eac44642b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2205df24a40e49189f4659ddb52a5407": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c606d1b744245f082fe14be1d3583b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43d533e2aadd468ea4df2ea73b7a8c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2245f3b285d43a2afad643bce20ba35",
              "IPY_MODEL_87c4fca857b344b684b654ed113597ec",
              "IPY_MODEL_bad6471fee444b4f84476d0c13668104"
            ],
            "layout": "IPY_MODEL_4f766201aa1f4223b11ff4a06747cced"
          }
        },
        "b2245f3b285d43a2afad643bce20ba35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e75bcc8e3ebb4c6b89da141e07b4e0df",
            "placeholder": "​",
            "style": "IPY_MODEL_87a03836c37143019662d8bb81d4640c",
            "value": "Epoch 0:   0%"
          }
        },
        "87c4fca857b344b684b654ed113597ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6e95484cb6c412a887a9ade477a7f22",
            "max": 9001,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_959a2db5b89649c1aa22a3723d5298c7",
            "value": 0
          }
        },
        "bad6471fee444b4f84476d0c13668104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_329a9d895c57421fa1d28d7a29f52607",
            "placeholder": "​",
            "style": "IPY_MODEL_6ff70e6d1dc74bd995c133f4d238fcd8",
            "value": " 0/9001 [00:00&lt;?, ?it/s]"
          }
        },
        "4f766201aa1f4223b11ff4a06747cced": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "e75bcc8e3ebb4c6b89da141e07b4e0df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87a03836c37143019662d8bb81d4640c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6e95484cb6c412a887a9ade477a7f22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "959a2db5b89649c1aa22a3723d5298c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "329a9d895c57421fa1d28d7a29f52607": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ff70e6d1dc74bd995c133f4d238fcd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}