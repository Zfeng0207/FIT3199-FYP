{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zfeng0207/FIT3199-FYP/blob/dev%2Fzfeng/hpa_pt_lightning_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0CUDImu9MEW",
        "outputId": "aeb28ba1-f7f0-4b75-ec88-8be6e10a2ef6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "h0CUDImu9MEW"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GfQLwvb-9N2C"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks (1)/ECG-MIMIC-main')"
      ],
      "id": "GfQLwvb-9N2C"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "K_PGqhC8-C_A"
      },
      "outputs": [],
      "source": [
        "!pip install -qqqq mlflow torchmetrics pytorch_lightning iterative-stratification"
      ],
      "id": "K_PGqhC8-C_A"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Number of sparse target class"
      ],
      "metadata": {
        "id": "NLniNpIM-xzq"
      },
      "id": "NLniNpIM-xzq"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"src/data/label_df.csv\")"
      ],
      "metadata": {
        "id": "FEMa8oLZf_SV"
      },
      "id": "FEMa8oLZf_SV",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_empty_labels(df, label_col=\"res\"):\n",
        "    \"\"\"\n",
        "    Counts how many samples in the DataFrame have all-zero labels.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame containing the dataset\n",
        "        label_col (str): Column name containing the multi-hot labels\n",
        "\n",
        "    Returns:\n",
        "        int: Number of rows with all-zero labels\n",
        "    \"\"\"\n",
        "    empty_count = 0\n",
        "\n",
        "    for label_str in df[label_col]:\n",
        "        label_array = np.fromstring(label_str.strip('[]'), sep=' ')  # Use np.fromstring instead of eval\n",
        "        if label_array.sum() == 0:\n",
        "            empty_count += 1\n",
        "\n",
        "    return empty_count\n"
      ],
      "metadata": {
        "id": "jXbW93xRpdQ0"
      },
      "id": "jXbW93xRpdQ0",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "num_empty = count_empty_labels(df, label_col=\"res\")\n",
        "print(f\"There are {num_empty} samples with all-zero labels.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jBtnc_hpeaH",
        "outputId": "031b2cba-ae79-42d5-c75f-942a53c41145"
      },
      "id": "6jBtnc_hpeaH",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 56715 samples with all-zero labels.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configurations"
      ],
      "metadata": {
        "id": "afP60juTq6cc"
      },
      "id": "afP60juTq6cc"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "eaccf6f7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-10T16:44:05.670902Z",
          "start_time": "2023-07-10T16:44:05.654877Z"
        },
        "id": "eaccf6f7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "import os\n",
        "import platform\n",
        "\n",
        "# You can define ROOT_PATH somewhere above\n",
        "ROOT_PATH = \"/content/drive/MyDrive/Colab Notebooks (1)/ECG-MIMIC-main/src\"\n",
        "\n",
        "@dataclass\n",
        "class DatasetConfig:\n",
        "    # ECG-specific\n",
        "    NUM_LEADS:    int = 12  # 12 ECG channels (leads)\n",
        "    NUM_CLASSES:  int = 12  # 12 ICD disease codes\n",
        "    VALID_PCT:  float = 0.1\n",
        "\n",
        "    # Dataset file and folder paths\n",
        "    TRAIN_CSV:   str = os.path.join(ROOT_PATH, \"data/train.csv\")  # Your preprocessed split CSV\n",
        "    TEST_CSV:    str = os.path.join(ROOT_PATH, \"data/test.csv\")\n",
        "    MEMMAP_FILE: str = os.path.join(ROOT_PATH, \"ecg_dataset\", \"data/memmap/memmap.npy\")\n",
        "    MEMMAP_META: str = os.path.join(ROOT_PATH, \"ecg_dataset\", \"data/memmap/memmap_meta.npz\")\n",
        "\n",
        "@dataclass\n",
        "class TrainingConfig:\n",
        "    BATCH_SIZE:      int = 32\n",
        "    NUM_EPOCHS:      int = 30  # Actual training epochs\n",
        "    INIT_LR:       float = 1e-3\n",
        "    NUM_WORKERS:     int = 0\n",
        "    OPTIMIZER_NAME:  str = \"Adam\"\n",
        "    WEIGHT_DECAY:  float = 1e-4\n",
        "    USE_SCHEDULER:  bool = True\n",
        "    SCHEDULER:       str = \"multi_step_lr\"  # or \"cosine_annealing\"\n",
        "    F1_METRIC_THRESH: float = 0.5\n",
        "    FREEZE_BACKBONE: bool = False\n",
        "\n",
        "    # (Optional) model name (if you want to log it somewhere)\n",
        "    MODEL_NAME:      str = \"resnet50\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "42c43a81",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-10T16:44:07.044656Z",
          "start_time": "2023-07-10T16:44:07.029033Z"
        },
        "id": "42c43a81",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def encode_label(label: list, num_classes=10):\n",
        "    \"\"\"\n",
        "    This functions converts labels into multi-hot encoding.\n",
        "    Handles both single ICD codes and lists of codes.\n",
        "    \"\"\"\n",
        "    target = torch.zeros(num_classes)\n",
        "\n",
        "    # If label is a single code, make it a list\n",
        "    if isinstance(label, str):\n",
        "        label = [label]\n",
        "\n",
        "    for l in label:\n",
        "        # Check if 'l' contains brackets (indicating list within a string)\n",
        "        if '[' in l or ']' in l:\n",
        "            l = l.strip('[]').replace(\"'\", \"\").split(\",\")  # Handle list-like strings\n",
        "            for code in l:\n",
        "                code = code.strip()  # Remove any whitespace around code\n",
        "                if code in icd_to_index:\n",
        "                    target[icd_to_index[code]] = 1.0\n",
        "        else:\n",
        "            l = l.strip()  # Remove any whitespace around code\n",
        "            if l in icd_to_index:\n",
        "                target[icd_to_index[l]] = 1.0\n",
        "    return target\n",
        "\n",
        "\n",
        "def decode_target(\n",
        "    target: list,\n",
        "    text_labels: bool = False,\n",
        "    threshold: float = 0.4,\n",
        "    cls_labels: dict = None,\n",
        "):\n",
        "    \"\"\"This function converts the labels from\n",
        "    probablities to outputs or string representations\n",
        "    \"\"\"\n",
        "\n",
        "    result = []\n",
        "    for i, x in enumerate(target):\n",
        "        if x >= threshold:\n",
        "            if text_labels:\n",
        "                result.append(cls_labels[i] + \"(\" + str(i) + \")\")\n",
        "            else:\n",
        "                result.append(str(i))\n",
        "    return \" \".join(result)\n",
        "\n",
        "\n",
        "# This function is used for reversing the Normalization step performed\n",
        "# during image preprocessing.\n",
        "# Note the mean and std values must match the ones used.\n",
        "\n",
        "def denormalize(tensors, *, mean, std):\n",
        "    \"\"\"Denormalizes image tensors using mean and std provided\n",
        "    and clip values between 0 and 1\"\"\"\n",
        "\n",
        "    for c in range(DatasetConfig.CHANNELS):\n",
        "        tensors[:, c, :, :].mul_(std[c]).add_(mean[c])\n",
        "\n",
        "    return torch.clamp(tensors, min=0.0, max=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary mapping ICD codes to index\n",
        "# icd_to_index = {code: idx for idx, code in enumerate(target_icd_codes)}\n"
      ],
      "metadata": {
        "id": "OmWT4BbUvxAM"
      },
      "id": "OmWT4BbUvxAM",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "aEHP8HuiG06q"
      },
      "id": "aEHP8HuiG06q"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9d77d248",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-10T16:44:07.060054Z",
          "start_time": "2023-07-10T16:44:07.044656Z"
        },
        "id": "9d77d248",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ECGDataset(Dataset):\n",
        "    def __init__(self, dataframe, memmap, normalize=True):\n",
        "        self.df = dataframe.reset_index(drop=True)\n",
        "        self.memmap = memmap\n",
        "        self.normalize = normalize\n",
        "        self.num_classes = 12\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.loc[idx]\n",
        "        start = int(row['start'])\n",
        "        length = int(row['length'])\n",
        "\n",
        "        signal = self.memmap[start : start + length * 12]\n",
        "        signal = signal.reshape(length, 12)\n",
        "\n",
        "        if self.normalize:\n",
        "            signal = (signal - np.nanmean(signal, axis=0)) / (np.nanstd(signal, axis=0) + 1e-6)\n",
        "\n",
        "        signal = torch.tensor(signal, dtype=torch.float32).permute(1, 0)  # [12, time]\n",
        "        label = np.fromstring(row['res'].strip('[]'), sep=' ', dtype=np.float32)  # Change this line\n",
        "\n",
        "        # Return label as float32\n",
        "        return signal, torch.tensor(label, dtype=torch.float32)  # Change this line"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Module"
      ],
      "metadata": {
        "id": "oll9G-J7G3GB"
      },
      "id": "oll9G-J7G3GB"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0d6a7838",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-10T16:44:07.092291Z",
          "start_time": "2023-07-10T16:44:07.060054Z"
        },
        "id": "0d6a7838",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold, MultilabelStratifiedShuffleSplit\n",
        "\n",
        "class ECGDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, dataframe, memmap, batch_size, num_workers, pin_memory, valid_pct, normalize=True, shuffle_validation=False): # Add shuffle_validation as a parameter\n",
        "        super().__init__()\n",
        "        self.dataframe = dataframe  # Full df\n",
        "        self.memmap = memmap\n",
        "        self.normalize = normalize\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        self.pin_memory = pin_memory\n",
        "        self.valid_pct = valid_pct\n",
        "        self.shuffle_validation = shuffle_validation\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        np.random.seed(42)\n",
        "\n",
        "        # 1. Prepare your multi-hot label matrix\n",
        "        label_cols = [\"res\"]\n",
        "        Y_wrong = self.dataframe[label_cols].values\n",
        "        Y = np.vstack([np.fromstring(row[0][1:-1], sep=' ') for row in Y_wrong])\n",
        "\n",
        "        # 2. First split into train_val and test\n",
        "        splitter = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "        train_val_idx, test_idx = next(splitter.split(self.dataframe, Y))\n",
        "\n",
        "        df_train_val = self.dataframe.iloc[train_val_idx].reset_index(drop=True)\n",
        "        df_test = self.dataframe.iloc[test_idx].reset_index(drop=True)\n",
        "\n",
        "        # 3. Now split train_val into train and val\n",
        "        splitter_val = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\n",
        "        Y_train_val_wrong = df_train_val[label_cols].values\n",
        "        Y_train_val = np.vstack([np.fromstring(row[0][1:-1], sep=' ', dtype=np.float64) for row in Y_train_val_wrong])\n",
        "\n",
        "        train_idx, val_idx = next(splitter_val.split(df_train_val, Y_train_val))\n",
        "\n",
        "        df_train = df_train_val.iloc[train_idx].reset_index(drop=True)\n",
        "        df_val = df_train_val.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "        # 4. Create datasets\n",
        "        self.train_ds = ECGDataset(\n",
        "            dataframe=df_train,\n",
        "            memmap=self.memmap,\n",
        "            normalize=self.normalize,\n",
        "        )\n",
        "\n",
        "        self.valid_ds = ECGDataset(\n",
        "            dataframe=df_val,\n",
        "            memmap=self.memmap,\n",
        "            normalize=self.normalize,\n",
        "        )\n",
        "\n",
        "        self.test_ds = ECGDataset(\n",
        "            dataframe=df_test,\n",
        "            memmap=self.memmap,\n",
        "            normalize=self.normalize,\n",
        "        )\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_ds,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=self.num_workers,\n",
        "            pin_memory=self.pin_memory,\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.valid_ds,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=self.shuffle_validation, # Use the instance variable\n",
        "            num_workers=self.num_workers,\n",
        "            pin_memory=self.pin_memory,\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        # Optional: If you set up a test set later\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "91ee71b8",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2023-07-10T16:43:46.064Z"
        },
        "id": "91ee71b8"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "\n",
        "def get_model(model_name: str, num_classes: int, freeze_backbone: bool= True):\n",
        "    \"\"\"A helper function to load and prepare any classification model\n",
        "    available in Torchvision for transfer learning or fine-tuning.\"\"\"\n",
        "\n",
        "    model = getattr(torchvision.models, model_name)(weights=\"DEFAULT\")\n",
        "\n",
        "    if freeze_backbone:\n",
        "        # Set all layer to be non-trainable\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    model_childrens = [name for name, _ in model.named_children()]\n",
        "\n",
        "    try:\n",
        "        final_layer_in_features = getattr(model, f\"{model_childrens[-1]}\")[-1].in_features\n",
        "    except Exception as e:\n",
        "        final_layer_in_features = getattr(model, f\"{model_childrens[-1]}\").in_features\n",
        "\n",
        "    new_output_layer = nn.Linear(\n",
        "        in_features=final_layer_in_features,\n",
        "        out_features=num_classes\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        getattr(model, f\"{model_childrens[-1]}\")[-1] = new_output_layer\n",
        "    except:\n",
        "        setattr(model, model_childrens[-1], new_output_layer)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f953896",
      "metadata": {
        "id": "3f953896"
      },
      "source": [
        "**Function usage example:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcT1fLY8wZVc",
        "outputId": "ea0ad0c6-6cd2-44fa-857f-aa380b7447cb"
      },
      "id": "qcT1fLY8wZVc",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (1.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "3696a2b6",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2023-07-10T16:43:46.070Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3696a2b6",
        "outputId": "bfcec07a-8ef9-4be3-908a-2b6be8083603"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===================================================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #                   Trainable\n",
              "===================================================================================================================\n",
              "ResNet                                   [32, 12]                  --                        True\n",
              "â”œâ”€Conv2d: 1-1                            [32, 64, 500, 1]          5,376                     True\n",
              "â”œâ”€BatchNorm2d: 1-2                       [32, 64, 500, 1]          128                       True\n",
              "â”œâ”€ReLU: 1-3                              [32, 64, 500, 1]          --                        --\n",
              "â”œâ”€MaxPool2d: 1-4                         [32, 64, 250, 1]          --                        --\n",
              "â”œâ”€Sequential: 1-5                        [32, 256, 250, 1]         --                        True\n",
              "â”‚    â””â”€Bottleneck: 2-1                   [32, 256, 250, 1]         75,008                    True\n",
              "â”‚    â””â”€Bottleneck: 2-2                   [32, 256, 250, 1]         70,400                    True\n",
              "â”‚    â””â”€Bottleneck: 2-3                   [32, 256, 250, 1]         70,400                    True\n",
              "â”œâ”€Sequential: 1-6                        [32, 512, 125, 1]         --                        True\n",
              "â”‚    â””â”€Bottleneck: 2-4                   [32, 512, 125, 1]         379,392                   True\n",
              "â”‚    â””â”€Bottleneck: 2-5                   [32, 512, 125, 1]         280,064                   True\n",
              "â”‚    â””â”€Bottleneck: 2-6                   [32, 512, 125, 1]         280,064                   True\n",
              "â”‚    â””â”€Bottleneck: 2-7                   [32, 512, 125, 1]         280,064                   True\n",
              "â”œâ”€Sequential: 1-7                        [32, 1024, 63, 1]         --                        True\n",
              "â”‚    â””â”€Bottleneck: 2-8                   [32, 1024, 63, 1]         1,512,448                 True\n",
              "â”‚    â””â”€Bottleneck: 2-9                   [32, 1024, 63, 1]         1,117,184                 True\n",
              "â”‚    â””â”€Bottleneck: 2-10                  [32, 1024, 63, 1]         1,117,184                 True\n",
              "â”‚    â””â”€Bottleneck: 2-11                  [32, 1024, 63, 1]         1,117,184                 True\n",
              "â”‚    â””â”€Bottleneck: 2-12                  [32, 1024, 63, 1]         1,117,184                 True\n",
              "â”‚    â””â”€Bottleneck: 2-13                  [32, 1024, 63, 1]         1,117,184                 True\n",
              "â”œâ”€Sequential: 1-8                        [32, 2048, 32, 1]         --                        True\n",
              "â”‚    â””â”€Bottleneck: 2-14                  [32, 2048, 32, 1]         6,039,552                 True\n",
              "â”‚    â””â”€Bottleneck: 2-15                  [32, 2048, 32, 1]         4,462,592                 True\n",
              "â”‚    â””â”€Bottleneck: 2-16                  [32, 2048, 32, 1]         4,462,592                 True\n",
              "â”œâ”€AdaptiveAvgPool2d: 1-9                 [32, 2048, 1, 1]          --                        --\n",
              "â”œâ”€Linear: 1-10                           [32, 12]                  24,588                    True\n",
              "===================================================================================================================\n",
              "Total params: 23,528,588\n",
              "Trainable params: 23,528,588\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.GIGABYTES): 37.12\n",
              "===================================================================================================================\n",
              "Input size (MB): 1.54\n",
              "Forward/backward pass size (MB): 965.28\n",
              "Params size (MB): 94.11\n",
              "Estimated Total Size (MB): 1060.93\n",
              "==================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from torchinfo import summary\n",
        "import torch.nn as nn\n",
        "\n",
        "# Suppose your ECG signals are 1000 time steps long\n",
        "TIME_LENGTH = 1000\n",
        "\n",
        "model = get_model(\n",
        "    model_name=TrainingConfig.MODEL_NAME,    # Should be \"resnet50\"\n",
        "    num_classes=DatasetConfig.NUM_CLASSES,\n",
        "    freeze_backbone=False,\n",
        ")\n",
        "\n",
        "# Correctly modify the first convolutional layer to accept 12 channels\n",
        "model.conv1 = nn.Conv2d(in_channels=12, out_channels=64, kernel_size=(7, 1), stride=(2, 1), padding=(3, 0), bias=False) # Reassign the layer\n",
        "\n",
        "# Proper ECG input shape\n",
        "summary(\n",
        "    model,\n",
        "    input_size=(TrainingConfig.BATCH_SIZE, DatasetConfig.NUM_LEADS, TIME_LENGTH, 1),  # (batch, channels=12, time, width=1)\n",
        "    depth=2,\n",
        "    device=\"cpu\",\n",
        "    col_names=[\"output_size\", \"num_params\", \"trainable\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Assuming 'df' is your DataFrame and 'res' is the column with labels\n",
        "# class_frequencies = []\n",
        "# for code in target_icd_codes:\n",
        "#     # Count occurrences of the current code in the 'res' column\n",
        "#     freq = df['res'].str.contains(code).sum()\n",
        "#     class_frequencies.append(freq)\n",
        "\n",
        "# # Convert the list to a PyTorch tensor\n",
        "# class_frequencies = torch.tensor(class_frequencies, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "yJudCyPyPuV5"
      },
      "id": "yJudCyPyPuV5",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2d03d271",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2023-07-10T16:43:46.077Z"
        },
        "id": "2d03d271"
      },
      "outputs": [],
      "source": [
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchmetrics import MeanMetric\n",
        "from torchmetrics.classification import MultilabelF1Score\n",
        "from torchvision.models import resnet50\n",
        "\n",
        "class ECGModel(pl.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_classes: int = 12,\n",
        "        init_lr: float = 1e-3,\n",
        "        optimizer_name: str = \"Adam\",\n",
        "        weight_decay: float = 1e-4,\n",
        "        use_scheduler: bool = False,\n",
        "        f1_metric_threshold: float = 0.5,\n",
        "        freeze_backbone: bool = False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # Save the arguments as hyperparameters.\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        # Build model\n",
        "        self.model = self.get_resnet50_for_ecg(num_classes, freeze_backbone)\n",
        "\n",
        "        # class_weights = torch.tensor([1 / freq for freq in class_frequencies])\n",
        "\n",
        "        # Loss function\n",
        "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "        # Metrics\n",
        "        self.mean_train_loss = MeanMetric()\n",
        "        self.mean_train_f1 = MultilabelF1Score(num_labels=num_classes, average=\"macro\", threshold=f1_metric_threshold)\n",
        "        self.mean_valid_loss = MeanMetric()\n",
        "        self.mean_valid_f1 = MultilabelF1Score(num_labels=num_classes, average=\"macro\", threshold=f1_metric_threshold)\n",
        "\n",
        "    def get_resnet50_for_ecg(self, num_classes, freeze_backbone):\n",
        "        model = resnet50(pretrained=True)\n",
        "\n",
        "        # Modify the first conv layer to accept 12 leads instead of 3 RGB channels\n",
        "        model.conv1 = nn.Conv2d(\n",
        "            in_channels=12,  # ECG leads\n",
        "            out_channels=64,\n",
        "            kernel_size=7,\n",
        "            stride=2,\n",
        "            padding=3,\n",
        "            bias=False,\n",
        "        )\n",
        "\n",
        "        # Modify the final fully connected layer to output num_classes\n",
        "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "        if freeze_backbone:\n",
        "            for name, param in model.named_parameters():\n",
        "                if \"fc\" not in name:  # Only leave the fc layer unfrozen\n",
        "                    param.requires_grad = False\n",
        "\n",
        "        return model\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: [batch_size, channels=12, time_steps]\n",
        "        # ResNet expects 2D images, so we need to simulate [batch, channels, height, width]\n",
        "        # Treat ECG [channels, time] as [channels, height, width=1]\n",
        "        x = x.unsqueeze(-1)  # [batch, 12, time, 1]\n",
        "        return self.model(x)\n",
        "\n",
        "    def training_step(self, batch, *args, **kwargs):\n",
        "        data, target = batch\n",
        "        logits = self(data)\n",
        "        loss = self.loss_fn(logits, target)\n",
        "\n",
        "        self.mean_train_loss(loss, weight=data.shape[0])\n",
        "        self.mean_train_f1(logits, target)\n",
        "\n",
        "        self.log(\"train/batch_loss\", self.mean_train_loss, prog_bar=True)\n",
        "        self.log(\"train/batch_f1\", self.mean_train_f1, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        self.log(\"train/loss\", self.mean_train_loss, prog_bar=True)\n",
        "        self.log(\"train/f1\", self.mean_train_f1, prog_bar=True)\n",
        "        self.log(\"step\", self.current_epoch)\n",
        "\n",
        "    def validation_step(self, batch, *args, **kwargs):\n",
        "        data, target = batch\n",
        "        logits = self(data)\n",
        "        loss = self.loss_fn(logits, target)\n",
        "\n",
        "        self.mean_valid_loss.update(loss, weight=data.shape[0])\n",
        "        self.mean_valid_f1.update(logits, target)\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        self.log(\"valid/loss\", self.mean_valid_loss, prog_bar=True)\n",
        "        self.log(\"valid/f1\", self.mean_valid_f1, prog_bar=True)\n",
        "        self.log(\"step\", self.current_epoch)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = getattr(torch.optim, self.hparams.optimizer_name)(\n",
        "            filter(lambda p: p.requires_grad, self.model.parameters()),\n",
        "            lr=self.hparams.init_lr,\n",
        "            weight_decay=self.hparams.weight_decay,\n",
        "        )\n",
        "\n",
        "        if self.hparams.use_scheduler:\n",
        "            lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
        "                optimizer,\n",
        "                milestones=[self.trainer.max_epochs // 2],\n",
        "                gamma=0.1,\n",
        "            )\n",
        "\n",
        "            return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler}\n",
        "        else:\n",
        "            return optimizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Initialization"
      ],
      "metadata": {
        "id": "gdZWRSKrG_EA"
      },
      "id": "gdZWRSKrG_EA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee9cff32-b77e-4fc6-8cde-c9d67b431263",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2023-07-10T16:43:46.083Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee9cff32-b77e-4fc6-8cde-c9d67b431263",
        "outputId": "97d89fae-c6ec-4c10-9594-52cff6caccb1",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n"
          ]
        }
      ],
      "source": [
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
        "\n",
        "# 1. Seed everything for reproducibility\n",
        "pl.seed_everything(42, workers=True)\n",
        "\n",
        "memmap_path = \"src/data/memmap/memmap.npy\"\n",
        "\n",
        "memmap_data = np.memmap(memmap_path, dtype=np.float32, mode='r')\n",
        "\n",
        "# Instantiate the ECGDataModule\n",
        "dm = ECGDataModule(\n",
        "    dataframe=df,            # Your loaded DataFrame\n",
        "    memmap=memmap_data,             # Your loaded memmap\n",
        "    # icd_to_index=icd_to_index,      # Your ICD code -> index mapping\n",
        "    batch_size=TrainingConfig.BATCH_SIZE,\n",
        "    num_workers=TrainingConfig.NUM_WORKERS,\n",
        "    pin_memory=torch.cuda.is_available(),\n",
        "    valid_pct=DatasetConfig.VALID_PCT,\n",
        ")\n",
        "\n",
        "# Prepare data (nothing to download for ECG, so will pass)\n",
        "dm.prepare_data()\n",
        "\n",
        "# Split dataset into training and validation sets\n",
        "dm.setup()\n",
        "\n",
        "# 4. Create ModelCheckpoint callback\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    monitor=\"valid/f1\",        # Monitor validation F1 score\n",
        "    mode=\"max\",                # Maximize F1\n",
        "    filename=\"ecg_epoch{epoch:03d}_vloss{valid/loss:.4f}_vf1{valid/f1:.4f}\",\n",
        "    auto_insert_metric_name=False,\n",
        "    save_top_k=1,              # Save the best model only\n",
        ")\n",
        "\n",
        "# 5. Create Learning Rate Monitor callback\n",
        "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fed847ae-7330-43f3-90fa-85bbd10f498f",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2023-07-10T16:43:46.088Z"
        },
        "id": "fed847ae-7330-43f3-90fa-85bbd10f498f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# # To reload tensorBoard\n",
        "# %reload_ext tensorboard\n",
        "\n",
        "# # logs folder path\n",
        "# %tensorboard --logdir=lightning_logs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83c7a942",
      "metadata": {
        "id": "83c7a942"
      },
      "source": [
        "**Train**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ECGModel(\n",
        "    num_classes=DatasetConfig.NUM_CLASSES,\n",
        "    init_lr=TrainingConfig.INIT_LR,\n",
        "    optimizer_name=TrainingConfig.OPTIMIZER_NAME,\n",
        "    weight_decay=TrainingConfig.WEIGHT_DECAY,\n",
        "    use_scheduler=TrainingConfig.USE_SCHEDULER,\n",
        "    f1_metric_threshold=TrainingConfig.F1_METRIC_THRESH,\n",
        "    freeze_backbone=TrainingConfig.FREEZE_BACKBONE,\n",
        ")"
      ],
      "metadata": {
        "id": "3hjB1kaxzcXW"
      },
      "id": "3hjB1kaxzcXW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "B_KsibxBZorA"
      },
      "id": "B_KsibxBZorA"
    },
    {
      "cell_type": "code",
      "source": [
        "# Access train_dataloader through the dm instance\n",
        "for batch in dm.train_dataloader():  # Call train_dataloader() on dm\n",
        "    signals, labels = batch\n",
        "    print(\"Sample labels:\", labels[:5])\n",
        "    print(\"Mean positive rate per label:\", labels.mean(dim=0))\n",
        "    break"
      ],
      "metadata": {
        "id": "0zv1qYEQpOUo"
      },
      "id": "0zv1qYEQpOUo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "909e0f0d",
      "metadata": {
        "id": "909e0f0d"
      },
      "outputs": [],
      "source": [
        "# Initializing the Trainer class object.\n",
        "# It uses 'Tensorboard' as its default logger.\n",
        "trainer = pl.Trainer(\n",
        "    accelerator=\"auto\", # Auto select the best hardware accelerator available\n",
        "    devices=\"auto\", # Auto select available devices for the accelerator (For eg. mutiple GPUs)\n",
        "    strategy=\"auto\", # Auto select the distributed training strategy.\n",
        "    max_epochs=TrainingConfig.NUM_EPOCHS, # Maximum number of epoch to train for.\n",
        "    deterministic=True, # For deteministic and reproducible training.\n",
        "    enable_model_summary=False, # Disable printing of model summary as we are using torchinfo.\n",
        "    callbacks=[model_checkpoint, lr_monitor],  # Declaring callbacks to use.\n",
        "    precision=\"16\", # Using Mixed Precision training.\n",
        "    logger=True, # Auto generate TensorBoard logs.\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.fit(model, dm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7714dd0f-502c-4297-ad13-a24655ca7c5d",
      "metadata": {
        "id": "7714dd0f-502c-4297-ad13-a24655ca7c5d"
      },
      "source": [
        "## 7 Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa9333e2",
      "metadata": {
        "id": "fa9333e2"
      },
      "source": [
        "To perform inference, first, we need to load the best checkpoint saved during training. We can do it simply by executing the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbe2954d-cb61-4855-a841-e399e3cb15a8",
      "metadata": {
        "id": "bbe2954d-cb61-4855-a841-e399e3cb15a8"
      },
      "outputs": [],
      "source": [
        "model = ProteinModel.load_from_checkpoint(CKPT_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0c9c470-95ff-47a2-9f7b-c19af1ea89c5",
      "metadata": {
        "id": "a0c9c470-95ff-47a2-9f7b-c19af1ea89c5"
      },
      "outputs": [],
      "source": [
        "# Initialize trainer class for inference.\n",
        "trainer = pl.Trainer(\n",
        "    accelerator=\"gpu\",\n",
        "    devices=1,\n",
        "    enable_checkpointing=False,\n",
        "    inference_mode=True,\n",
        ")\n",
        "\n",
        "# Run evaluation.\n",
        "data_module.setup()\n",
        "valid_loader = data_module.val_dataloader()\n",
        "trainer.validate(model=model, dataloaders=valid_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44acfc02",
      "metadata": {
        "id": "44acfc02"
      },
      "source": [
        "## 8 Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41e9dc0e",
      "metadata": {
        "id": "41e9dc0e"
      },
      "source": [
        "Multi-label image classification is a fundamental and necessary task in many real-world scenarios where an image may contain more than one object or feature of interest. Unlike single-label classification, where each image is associated with only one label or class, multi-label classification acknowledges the inherent complexity and variety in real-world images by allowing them to be associated with multiple labels or classes simultaneously. This is particularly relevant in various domains. For example, in medical imaging, a scan may reveal multiple conditions or observations. Similarly, in social media, a photo may contain multiple people, objects, or activities. Additionally, in the field of autonomous vehicles, a single frame of a video feed may contain cars, pedestrians, signs, and more. By recognizing and categorizing multiple elements within a single image, multi-label classification provides a more comprehensive and nuanced understanding of the visual world, enabling us to build more effective and versatile AI systems.\n",
        "\n",
        "To summarise this articleðŸ“œ, we covered a comprehensive list of related topics:\n",
        "\n",
        "1. We explored image classification, highlighting the distinction between multi-class (one label per image) and multi-label (multiple labels per image) types.\n",
        "\n",
        "2. We emphasized the unique post-processing and loss function requirements in multi-label classification, which set it apart from traditional classifications.\n",
        "\n",
        "3. We utilized a subset of Kaggle's \"Human Protein Atlas Image Classification\" challenge to illustrate medical multi-label image classification in PyTorch.\n",
        "\n",
        "4. We streamlined our code and improve readability using the PyTorch-Lightning library, which simplifies PyTorch's complex aspects.\n",
        "\n",
        "5.We leveraged the pre-trained EfficientNetv2-small model from torchvision as our starting point and then fine-tune it for our specific task.\n",
        "\n",
        "6. We designed a user-friendly interface using the Gradio app, making our medical multi-label image classification model accessible to everyone."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "379.387px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}