{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data_path = 'preprocessed_data_without_text.csv'\n",
    "preprocessed_data = pd.read_csv(preprocessed_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = preprocessed_data['category']\n",
    "X = preprocessed_data.drop(columns=['category'])\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.2, random_state=42, stratify=y_train_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempted to annotate data to deal with high volume of wrongly predicted 'Uncategorized' class. But metrics show no improvement.\n",
    "\n",
    "- Oversample and undersample to strike a balance between classes\n",
    "- Reduce size to mitigate model training runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\V372125\\OneDrive - PPG Industries, Inc\\Documents\\moneylion-assessment\\mls-assessment\\mls_env\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\V372125\\OneDrive - PPG Industries, Inc\\Documents\\moneylion-assessment\\mls-assessment\\mls_env\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    }
   ],
   "source": [
    "# Oversampling and Undersampling Strategy\n",
    "\n",
    "max_samples = 20000  # upper limit for large categories\n",
    "min_samples = 1000   # lower limit for small categories\n",
    "\n",
    "# compute class distribution in training set\n",
    "class_counts = np.bincount(y_train)  # Count occurrences of each class\n",
    "classes = np.unique(y_train)\n",
    "\n",
    "# define sampling strategies dynamically\n",
    "smote_strategy = {}\n",
    "undersample_strategy = {cls: int(count * 0.7) for cls, count in y_train.value_counts().items()}\n",
    "\n",
    "for cls, count in zip(classes, class_counts):\n",
    "    if count < min_samples:\n",
    "        smote_strategy[cls] = min_samples  \n",
    "    elif count > max_samples:\n",
    "        undersample_strategy[cls] = max_samples  \n",
    "\n",
    "k_neighbors = min(3, min(class_counts) - 1) \n",
    "\n",
    "smote = SMOTE(sampling_strategy=smote_strategy, k_neighbors=k_neighbors)\n",
    "undersample = RandomUnderSampler(sampling_strategy=undersample_strategy)\n",
    "\n",
    "resampling_pipeline = Pipeline([\n",
    "    ('smote', smote),\n",
    "    ('undersample', undersample)\n",
    "])\n",
    "\n",
    "X_train_resampled, y_train_resampled = resampling_pipeline.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115917, 35)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled, y_train_resampled = resampling_pipeline.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Convert y_pred to a Pandas Series\n",
    "y_train_resampled = pd.Series(y_train_resampled)\n",
    "\n",
    "# Get category distribution\n",
    "label = y_train_resampled.value_counts().index\n",
    "values = y_train_resampled.value_counts().values\n",
    "\n",
    "# Map encoded labels back to original category names (if needed)\n",
    "if isinstance(label[0], (int, float)):  # Check if labels are numeric\n",
    "    label = [class_mapping[lbl] for lbl in label]  # Convert to original labels\n",
    "\n",
    "# Plot the distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(label, values, color=\"maroon\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Category\")\n",
    "plt.title(\"Category Distribution\")\n",
    "plt.gca().invert_yaxis()  # Invert y-axis for better readability\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\V372125\\OneDrive - PPG Industries, Inc\\Documents\\moneylion-assessment\\mls-assessment\\mls_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\V372125\\OneDrive - PPG Industries, Inc\\Documents\\moneylion-assessment\\mls-assessment\\mls_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\V372125\\OneDrive - PPG Industries, Inc\\Documents\\moneylion-assessment\\mls-assessment\\mls_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Validation Metrics:\n",
      "F1 Score: 0.0943\n",
      "Precision: 0.0660\n",
      "Recall: 0.1690\n",
      "Accuracy: 0.1690\n",
      "\n",
      "Test Metrics:\n",
      "F1 Score: 0.0957\n",
      "Precision: 0.0670\n",
      "Recall: 0.1716\n",
      "Accuracy: 0.1716\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\V372125\\OneDrive - PPG Industries, Inc\\Documents\\moneylion-assessment\\mls-assessment\\mls_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\V372125\\OneDrive - PPG Industries, Inc\\Documents\\moneylion-assessment\\mls-assessment\\mls_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest\n",
      "Validation Metrics:\n",
      "F1 Score: 0.6828\n",
      "Precision: 0.6911\n",
      "Recall: 0.6867\n",
      "Accuracy: 0.6867\n",
      "\n",
      "Test Metrics:\n",
      "F1 Score: 0.6821\n",
      "Precision: 0.6903\n",
      "Recall: 0.6865\n",
      "Accuracy: 0.6865\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\V372125\\OneDrive - PPG Industries, Inc\\Documents\\moneylion-assessment\\mls-assessment\\mls_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\V372125\\OneDrive - PPG Industries, Inc\\Documents\\moneylion-assessment\\mls-assessment\\mls_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: KNN\n",
      "Validation Metrics:\n",
      "F1 Score: 0.1667\n",
      "Precision: 0.1746\n",
      "Recall: 0.1668\n",
      "Accuracy: 0.1668\n",
      "\n",
      "Test Metrics:\n",
      "F1 Score: 0.1681\n",
      "Precision: 0.1775\n",
      "Recall: 0.1678\n",
      "Accuracy: 0.1678\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\V372125\\OneDrive - PPG Industries, Inc\\Documents\\moneylion-assessment\\mls-assessment\\mls_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\V372125\\OneDrive - PPG Industries, Inc\\Documents\\moneylion-assessment\\mls-assessment\\mls_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Naive Bayes\n",
      "Validation Metrics:\n",
      "F1 Score: 0.0162\n",
      "Precision: 0.0534\n",
      "Recall: 0.0901\n",
      "Accuracy: 0.0901\n",
      "\n",
      "Test Metrics:\n",
      "F1 Score: 0.0163\n",
      "Precision: 0.0607\n",
      "Recall: 0.0902\n",
      "Accuracy: 0.0902\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\V372125\\OneDrive - PPG Industries, Inc\\Documents\\moneylion-assessment\\mls-assessment\\mls_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Gradient Boosting\n",
      "Validation Metrics:\n",
      "F1 Score: 0.5571\n",
      "Precision: 0.5893\n",
      "Recall: 0.5601\n",
      "Accuracy: 0.5601\n",
      "\n",
      "Test Metrics:\n",
      "F1 Score: 0.5579\n",
      "Precision: 0.5890\n",
      "Recall: 0.5617\n",
      "Accuracy: 0.5617\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\V372125\\OneDrive - PPG Industries, Inc\\Documents\\moneylion-assessment\\mls-assessment\\mls_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Decision Tree\n",
      "Validation Metrics:\n",
      "F1 Score: 0.6260\n",
      "Precision: 0.6263\n",
      "Recall: 0.6259\n",
      "Accuracy: 0.6259\n",
      "\n",
      "Test Metrics:\n",
      "F1 Score: 0.6271\n",
      "Precision: 0.6272\n",
      "Recall: 0.6272\n",
      "Accuracy: 0.6272\n",
      "--------------------------------------------------\n",
      "Model: AdaBoost\n",
      "Validation Metrics:\n",
      "F1 Score: 0.1964\n",
      "Precision: 0.2369\n",
      "Recall: 0.2483\n",
      "Accuracy: 0.2483\n",
      "\n",
      "Test Metrics:\n",
      "F1 Score: 0.1962\n",
      "Precision: 0.2347\n",
      "Recall: 0.2482\n",
      "Accuracy: 0.2482\n",
      "--------------------------------------------------\n",
      "Accuracy comparison across models:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\V372125\\OneDrive - PPG Industries, Inc\\Documents\\moneylion-assessment\\mls-assessment\\mls_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\V372125\\OneDrive - PPG Industries, Inc\\Documents\\moneylion-assessment\\mls-assessment\\mls_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Define the models to test\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    # 'SVC': SVC(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "# Loop through models, train and evaluate each\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_val_pred = model.predict(X_val)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics for validation set\n",
    "    val_f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "    val_precision = precision_score(y_val, y_val_pred, average='weighted')\n",
    "    val_recall = recall_score(y_val, y_val_pred, average='weighted')\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "    # Calculate metrics for test set\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "    test_precision = precision_score(y_test, y_test_pred, average='weighted')\n",
    "    test_recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    # Print the metrics\n",
    "    print(f\"Model: {name}\")\n",
    "    print(\"Validation Metrics:\")\n",
    "    print(f\"F1 Score: {val_f1:.4f}\")\n",
    "    print(f\"Precision: {val_precision:.4f}\")\n",
    "    print(f\"Recall: {val_recall:.4f}\")\n",
    "    print(f\"Accuracy: {val_accuracy:.4f}\")\n",
    "    print()\n",
    "    print(\"Test Metrics:\")\n",
    "    print(f\"F1 Score: {test_f1:.4f}\")\n",
    "    print(f\"Precision: {test_precision:.4f}\")\n",
    "    print(f\"Recall: {test_recall:.4f}\")\n",
    "    print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# If you'd like to compare just accuracy, you can sort models by accuracy\n",
    "accuracy_comparison = sorted(results.items(), key=lambda x: x[1]['accuracy'], reverse=True)\n",
    "\n",
    "print(\"Accuracy comparison across models:\")\n",
    "for name, result in accuracy_comparison:\n",
    "    print(f\"{name}: {result['accuracy']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"Objective function to optimize Random Forest hyperparameters.\"\"\"\n",
    "    \n",
    "    # hyperparameter space\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 500) \n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 30)  \n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 20)  \n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 20)  \n",
    "    max_features = trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None])  \n",
    "    \n",
    "    # define and train the Random Forest model\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    # compute weighted F1-score\n",
    "    f1 = f1_score(y_val, y_pred, average=\"weighted\")\n",
    "    \n",
    "    return f1  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-10 19:54:03,411] A new study created in memory with name: no-name-d1baefbb-73ef-476d-ac80-33ce9e322315\n",
      "[I 2025-02-10 19:54:19,350] Trial 0 finished with value: 0.5913757647928425 and parameters: {'n_estimators': 182, 'max_depth': 26, 'min_samples_split': 2, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.5913757647928425.\n",
      "[I 2025-02-10 19:54:38,605] Trial 1 finished with value: 0.4688296155401625 and parameters: {'n_estimators': 375, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 14, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.5913757647928425.\n",
      "[I 2025-02-10 19:55:45,770] Trial 2 finished with value: 0.31618785373085473 and parameters: {'n_estimators': 478, 'max_depth': 4, 'min_samples_split': 17, 'min_samples_leaf': 11, 'max_features': None}. Best is trial 0 with value: 0.5913757647928425.\n",
      "[I 2025-02-10 19:55:54,594] Trial 3 finished with value: 0.48701052722617866 and parameters: {'n_estimators': 197, 'max_depth': 10, 'min_samples_split': 16, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 0 with value: 0.5913757647928425.\n",
      "[I 2025-02-10 19:57:16,307] Trial 4 finished with value: 0.5676450392357566 and parameters: {'n_estimators': 237, 'max_depth': 15, 'min_samples_split': 14, 'min_samples_leaf': 12, 'max_features': None}. Best is trial 0 with value: 0.5913757647928425.\n",
      "[I 2025-02-10 19:58:50,130] Trial 5 finished with value: 0.5995255929352571 and parameters: {'n_estimators': 200, 'max_depth': 23, 'min_samples_split': 6, 'min_samples_leaf': 17, 'max_features': None}. Best is trial 5 with value: 0.5995255929352571.\n",
      "[I 2025-02-10 19:59:23,995] Trial 6 finished with value: 0.5859975538362342 and parameters: {'n_estimators': 438, 'max_depth': 25, 'min_samples_split': 8, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 5 with value: 0.5995255929352571.\n",
      "[I 2025-02-10 19:59:55,914] Trial 7 finished with value: 0.5633099445226527 and parameters: {'n_estimators': 420, 'max_depth': 25, 'min_samples_split': 11, 'min_samples_leaf': 17, 'max_features': 'log2'}. Best is trial 5 with value: 0.5995255929352571.\n",
      "[I 2025-02-10 20:00:06,739] Trial 8 finished with value: 0.5630143105757274 and parameters: {'n_estimators': 146, 'max_depth': 30, 'min_samples_split': 19, 'min_samples_leaf': 18, 'max_features': 'log2'}. Best is trial 5 with value: 0.5995255929352571.\n",
      "[I 2025-02-10 20:00:55,901] Trial 9 finished with value: 0.4012435456351641 and parameters: {'n_estimators': 333, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 14, 'max_features': None}. Best is trial 5 with value: 0.5995255929352571.\n",
      "[I 2025-02-10 20:01:21,096] Trial 10 finished with value: 0.6190582839936373 and parameters: {'n_estimators': 60, 'max_depth': 19, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 10 with value: 0.6190582839936373.\n",
      "[I 2025-02-10 20:01:48,230] Trial 11 finished with value: 0.6177029843350396 and parameters: {'n_estimators': 50, 'max_depth': 19, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 10 with value: 0.6190582839936373.\n",
      "[I 2025-02-10 20:02:18,389] Trial 12 finished with value: 0.6098877182664407 and parameters: {'n_estimators': 69, 'max_depth': 18, 'min_samples_split': 11, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 10 with value: 0.6190582839936373.\n",
      "[I 2025-02-10 20:02:46,574] Trial 13 finished with value: 0.5970831796107869 and parameters: {'n_estimators': 74, 'max_depth': 17, 'min_samples_split': 13, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 10 with value: 0.6190582839936373.\n",
      "[I 2025-02-10 20:03:44,642] Trial 14 finished with value: 0.6254440616462892 and parameters: {'n_estimators': 130, 'max_depth': 21, 'min_samples_split': 9, 'min_samples_leaf': 5, 'max_features': None}. Best is trial 14 with value: 0.6254440616462892.\n",
      "[I 2025-02-10 20:04:22,221] Trial 15 finished with value: 0.564634817262526 and parameters: {'n_estimators': 123, 'max_depth': 14, 'min_samples_split': 8, 'min_samples_leaf': 5, 'max_features': None}. Best is trial 14 with value: 0.6254440616462892.\n",
      "[I 2025-02-10 20:04:42,580] Trial 16 finished with value: 0.5905204702402926 and parameters: {'n_estimators': 267, 'max_depth': 22, 'min_samples_split': 3, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 14 with value: 0.6254440616462892.\n",
      "[I 2025-02-10 20:05:34,952] Trial 17 finished with value: 0.6252654669178496 and parameters: {'n_estimators': 120, 'max_depth': 21, 'min_samples_split': 9, 'min_samples_leaf': 5, 'max_features': None}. Best is trial 14 with value: 0.6254440616462892.\n",
      "[I 2025-02-10 20:06:23,659] Trial 18 finished with value: 0.642340814437297 and parameters: {'n_estimators': 117, 'max_depth': 28, 'min_samples_split': 8, 'min_samples_leaf': 5, 'max_features': None}. Best is trial 18 with value: 0.642340814437297.\n",
      "[I 2025-02-10 20:06:46,668] Trial 19 finished with value: 0.5993902339886953 and parameters: {'n_estimators': 309, 'max_depth': 30, 'min_samples_split': 13, 'min_samples_leaf': 7, 'max_features': 'sqrt'}. Best is trial 18 with value: 0.642340814437297.\n",
      "[I 2025-02-10 20:07:53,200] Trial 20 finished with value: 0.6505570061140229 and parameters: {'n_estimators': 153, 'max_depth': 29, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 20 with value: 0.6505570061140229.\n",
      "[I 2025-02-10 20:08:58,113] Trial 21 finished with value: 0.6540867594354163 and parameters: {'n_estimators': 145, 'max_depth': 28, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 21 with value: 0.6540867594354163.\n",
      "[I 2025-02-10 20:10:39,486] Trial 22 finished with value: 0.6532361375541471 and parameters: {'n_estimators': 173, 'max_depth': 27, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 21 with value: 0.6540867594354163.\n",
      "[I 2025-02-10 20:13:50,263] Trial 23 finished with value: 0.653440545516046 and parameters: {'n_estimators': 230, 'max_depth': 27, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 21 with value: 0.6540867594354163.\n",
      "[I 2025-02-10 20:16:06,898] Trial 24 finished with value: 0.6535977224345749 and parameters: {'n_estimators': 241, 'max_depth': 27, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 21 with value: 0.6540867594354163.\n",
      "[I 2025-02-10 20:18:22,306] Trial 25 finished with value: 0.6493952460676296 and parameters: {'n_estimators': 238, 'max_depth': 25, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 21 with value: 0.6540867594354163.\n",
      "[I 2025-02-10 20:20:55,390] Trial 26 finished with value: 0.6263291150423581 and parameters: {'n_estimators': 246, 'max_depth': 23, 'min_samples_split': 6, 'min_samples_leaf': 7, 'max_features': None}. Best is trial 21 with value: 0.6540867594354163.\n",
      "[I 2025-02-10 20:23:39,954] Trial 27 finished with value: 0.5977554622362736 and parameters: {'n_estimators': 297, 'max_depth': 28, 'min_samples_split': 4, 'min_samples_leaf': 20, 'max_features': None}. Best is trial 21 with value: 0.6540867594354163.\n",
      "[I 2025-02-10 20:24:07,226] Trial 28 finished with value: 0.6319173505271187 and parameters: {'n_estimators': 215, 'max_depth': 27, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 21 with value: 0.6540867594354163.\n",
      "[I 2025-02-10 20:24:47,370] Trial 29 finished with value: 0.5919965331600056 and parameters: {'n_estimators': 361, 'max_depth': 26, 'min_samples_split': 2, 'min_samples_leaf': 8, 'max_features': 'log2'}. Best is trial 21 with value: 0.6540867594354163.\n",
      "[I 2025-02-10 20:25:25,930] Trial 30 finished with value: 0.6288249461792597 and parameters: {'n_estimators': 281, 'max_depth': 23, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 21 with value: 0.6540867594354163.\n",
      "[I 2025-02-10 20:27:48,400] Trial 31 finished with value: 0.6535784923814338 and parameters: {'n_estimators': 184, 'max_depth': 27, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 21 with value: 0.6540867594354163.\n",
      "[I 2025-02-10 20:30:04,848] Trial 32 finished with value: 0.6508700864496768 and parameters: {'n_estimators': 179, 'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 21 with value: 0.6540867594354163.\n",
      "[I 2025-02-10 20:32:17,245] Trial 33 finished with value: 0.6307670872920702 and parameters: {'n_estimators': 217, 'max_depth': 25, 'min_samples_split': 3, 'min_samples_leaf': 7, 'max_features': None}. Best is trial 21 with value: 0.6540867594354163.\n",
      "[I 2025-02-10 20:33:36,971] Trial 34 finished with value: 0.653447437416421 and parameters: {'n_estimators': 99, 'max_depth': 28, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 21 with value: 0.6540867594354163.\n",
      "[I 2025-02-10 20:34:47,105] Trial 35 finished with value: 0.5562273015768222 and parameters: {'n_estimators': 161, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 21 with value: 0.6540867594354163.\n",
      "[I 2025-02-10 20:35:39,929] Trial 36 finished with value: 0.6136252140541039 and parameters: {'n_estimators': 81, 'max_depth': 28, 'min_samples_split': 7, 'min_samples_leaf': 13, 'max_features': None}. Best is trial 21 with value: 0.6540867594354163.\n",
      "[I 2025-02-10 20:35:46,154] Trial 37 finished with value: 0.4984925076069249 and parameters: {'n_estimators': 102, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}. Best is trial 21 with value: 0.6540867594354163.\n",
      "[I 2025-02-10 20:36:09,288] Trial 38 finished with value: 0.6073376262367469 and parameters: {'n_estimators': 200, 'max_depth': 24, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 21 with value: 0.6540867594354163.\n",
      "[I 2025-02-10 20:38:23,216] Trial 39 finished with value: 0.6251884493318501 and parameters: {'n_estimators': 186, 'max_depth': 26, 'min_samples_split': 3, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 21 with value: 0.6540867594354163.\n",
      "[I 2025-02-10 20:44:34,542] Trial 40 finished with value: 0.6404955293800683 and parameters: {'n_estimators': 496, 'max_depth': 29, 'min_samples_split': 7, 'min_samples_leaf': 6, 'max_features': None}. Best is trial 21 with value: 0.6540867594354163.\n",
      "[I 2025-02-10 20:47:55,396] Trial 41 finished with value: 0.6542367765718023 and parameters: {'n_estimators': 267, 'max_depth': 27, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 41 with value: 0.6542367765718023.\n",
      "[I 2025-02-10 20:48:24,097] Trial 42 finished with value: 0.245972671265173 and parameters: {'n_estimators': 263, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 41 with value: 0.6542367765718023.\n",
      "[I 2025-02-10 20:49:25,659] Trial 43 finished with value: 0.6291227059524053 and parameters: {'n_estimators': 103, 'max_depth': 24, 'min_samples_split': 20, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 41 with value: 0.6542367765718023.\n",
      "[I 2025-02-10 20:49:37,744] Trial 44 finished with value: 0.4147028875337238 and parameters: {'n_estimators': 328, 'max_depth': 7, 'min_samples_split': 16, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 41 with value: 0.6542367765718023.\n",
      "[I 2025-02-10 20:50:51,412] Trial 45 finished with value: 0.6395976696829963 and parameters: {'n_estimators': 144, 'max_depth': 29, 'min_samples_split': 6, 'min_samples_leaf': 6, 'max_features': None}. Best is trial 41 with value: 0.6542367765718023.\n",
      "[I 2025-02-10 20:51:38,993] Trial 46 finished with value: 0.6500287657037247 and parameters: {'n_estimators': 89, 'max_depth': 26, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 41 with value: 0.6542367765718023.\n",
      "[I 2025-02-10 20:53:44,348] Trial 47 finished with value: 0.6371605962139271 and parameters: {'n_estimators': 254, 'max_depth': 21, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 41 with value: 0.6542367765718023.\n",
      "[I 2025-02-10 20:56:02,368] Trial 48 finished with value: 0.6186305193462153 and parameters: {'n_estimators': 285, 'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 12, 'max_features': None}. Best is trial 41 with value: 0.6542367765718023.\n",
      "[I 2025-02-10 20:56:22,774] Trial 49 finished with value: 0.6073661456857237 and parameters: {'n_estimators': 213, 'max_depth': 24, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 41 with value: 0.6542367765718023.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_estimators': 267, 'max_depth': 27, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': None}\n",
      "Best F1 Score: 0.6542367765718023\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")  # Maximize F1-score\n",
    "study.optimize(objective, n_trials=50)  # Run 50 trials\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n",
    "print(\"Best F1 Score:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "\n",
    "best_model = RandomForestClassifier(**best_params, random_state=42, n_jobs=-1)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# save the model param to a pickle file\n",
    "joblib.dump(best_model, \"best_random_forest.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mls_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
